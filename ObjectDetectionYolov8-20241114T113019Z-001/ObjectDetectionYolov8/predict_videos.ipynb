{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMhBddUgrnvPgRILs+kGBuU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4INQgtIn76mZ","executionInfo":{"status":"ok","timestamp":1731508874060,"user_tz":-180,"elapsed":4287,"user":{"displayName":"BugBeauty","userId":"14397405117155400645"}},"outputId":"7263c5d2-a07f-495d-f69b-0e2b4a87f608"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: ultralytics in /usr/local/lib/python3.10/dist-packages (8.3.29)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n","Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n","Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.8.0)\n","Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (11.0.0)\n","Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n","Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.5.0+cu121)\n","Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.20.0+cu121)\n","Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.6)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.2)\n","Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.2)\n","Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.11)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.54.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n"]}],"source":["!pip install ultralytics opencv-python"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2CNkYDel8B7Y","executionInfo":{"status":"ok","timestamp":1731508876397,"user_tz":-180,"elapsed":2342,"user":{"displayName":"BugBeauty","userId":"14397405117155400645"}},"outputId":"1f31eba2-5c1e-4879-ee83-5fa675b8ab30"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["video_path = '/content/gdrive/My Drive/ComputerVisionEngineer/ObjectDetectionYolov8/videos/alpacaVideos1.mp4'\n","video_path_out = '/content/gdrive/My Drive/ComputerVisionEngineer/ObjectDetectionYolov8/videos/alpacaVideos1_out.mp4'"],"metadata":{"id":"E8nlS9Qi8NHT","executionInfo":{"status":"ok","timestamp":1731508876397,"user_tz":-180,"elapsed":5,"user":{"displayName":"BugBeauty","userId":"14397405117155400645"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["import cv2\n","import os\n","from ultralytics import YOLO\n","\n","# Video dosyasının yolu\n","video_path = '/content/gdrive/My Drive/ComputerVisionEngineer/ObjectDetectionYolov8/videos/alpacaVideos1.mp4'\n","video_path_out = '/content/gdrive/My Drive/ComputerVisionEngineer/ObjectDetectionYolov8/videos/alpacaVideos1_out.mp4'\n","\n","cap = cv2.VideoCapture(video_path)\n","ret, frame = cap.read()\n","\n","# Frame boyutlarını al\n","H, W, _ = frame.shape\n","out = cv2.VideoWriter(video_path_out, cv2.VideoWriter_fourcc(*'MP4V'), int(cap.get(cv2.CAP_PROP_FPS)), (W, H))\n","\n","# Modelin yolu\n","model_path = '/content/gdrive/My Drive/ComputerVisionEngineer/ObjectDetectionYolov8/runs/detect/train82/weights/best.pt'\n","\n","# Modeli yükle\n","model = YOLO(model_path)\n","\n","threshold = 0.5\n","\n","while ret:\n","    results = model(frame)[0]\n","\n","    # Sonuçları işleyin\n","    for result in results.boxes.data.tolist():\n","        x1, y1, x2, y2, score, class_id = result\n","\n","        if score > threshold:\n","            cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 4)\n","            cv2.putText(frame, results.names[int(class_id)].upper(), (int(x1), int(y1 - 10)),\n","                        cv2.FONT_HERSHEY_SIMPLEX, 1.3, (0, 255, 0), 3, cv2.LINE_AA)\n","\n","    out.write(frame)\n","    ret, frame = cap.read()\n","\n","# Kaynakları serbest bırak\n","cap.release()\n","out.release()\n","cv2.destroyAllWindows()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pb2YoMG38tOJ","executionInfo":{"status":"ok","timestamp":1731508931779,"user_tz":-180,"elapsed":55386,"user":{"displayName":"BugBeauty","userId":"14397405117155400645"}},"outputId":"a8295350-f558-4a6c-a8bb-c16e27a38c96"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","0: 384x640 4 alpacas, 152.0ms\n","Speed: 7.0ms preprocess, 152.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 132.2ms\n","Speed: 4.3ms preprocess, 132.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 5 alpacas, 145.8ms\n","Speed: 6.0ms preprocess, 145.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 5 alpacas, 195.9ms\n","Speed: 6.4ms preprocess, 195.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 216.6ms\n","Speed: 4.3ms preprocess, 216.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 134.2ms\n","Speed: 6.6ms preprocess, 134.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 130.7ms\n","Speed: 4.5ms preprocess, 130.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 141.8ms\n","Speed: 4.3ms preprocess, 141.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 129.3ms\n","Speed: 4.5ms preprocess, 129.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 120.9ms\n","Speed: 4.9ms preprocess, 120.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 135.6ms\n","Speed: 4.3ms preprocess, 135.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 124.7ms\n","Speed: 8.4ms preprocess, 124.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 143.5ms\n","Speed: 4.2ms preprocess, 143.5ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 125.4ms\n","Speed: 2.8ms preprocess, 125.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 124.8ms\n","Speed: 4.5ms preprocess, 124.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 130.0ms\n","Speed: 4.5ms preprocess, 130.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 134.5ms\n","Speed: 4.1ms preprocess, 134.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 119.4ms\n","Speed: 7.3ms preprocess, 119.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 148.3ms\n","Speed: 5.4ms preprocess, 148.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 144.8ms\n","Speed: 4.9ms preprocess, 144.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 120.9ms\n","Speed: 3.9ms preprocess, 120.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 126.9ms\n","Speed: 5.6ms preprocess, 126.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 141.5ms\n","Speed: 4.6ms preprocess, 141.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 123.0ms\n","Speed: 5.9ms preprocess, 123.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 136.6ms\n","Speed: 7.3ms preprocess, 136.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 126.7ms\n","Speed: 3.7ms preprocess, 126.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 119.9ms\n","Speed: 4.3ms preprocess, 119.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 120.8ms\n","Speed: 4.5ms preprocess, 120.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 124.8ms\n","Speed: 4.4ms preprocess, 124.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 125.5ms\n","Speed: 5.4ms preprocess, 125.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 138.1ms\n","Speed: 4.1ms preprocess, 138.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 127.9ms\n","Speed: 4.1ms preprocess, 127.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 124.9ms\n","Speed: 4.1ms preprocess, 124.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 133.6ms\n","Speed: 5.0ms preprocess, 133.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 212.6ms\n","Speed: 5.3ms preprocess, 212.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 206.9ms\n","Speed: 5.5ms preprocess, 206.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 199.2ms\n","Speed: 4.0ms preprocess, 199.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 130.4ms\n","Speed: 3.8ms preprocess, 130.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 129.7ms\n","Speed: 4.1ms preprocess, 129.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 156.8ms\n","Speed: 4.2ms preprocess, 156.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 136.0ms\n","Speed: 4.0ms preprocess, 136.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 124.4ms\n","Speed: 3.8ms preprocess, 124.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 117.3ms\n","Speed: 5.8ms preprocess, 117.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 124.0ms\n","Speed: 4.6ms preprocess, 124.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 135.2ms\n","Speed: 3.7ms preprocess, 135.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 204.4ms\n","Speed: 6.3ms preprocess, 204.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 200.7ms\n","Speed: 5.6ms preprocess, 200.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 187.4ms\n","Speed: 4.4ms preprocess, 187.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 202.6ms\n","Speed: 4.3ms preprocess, 202.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 215.6ms\n","Speed: 5.4ms preprocess, 215.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 196.2ms\n","Speed: 4.2ms preprocess, 196.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 189.9ms\n","Speed: 6.4ms preprocess, 189.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 186.9ms\n","Speed: 6.7ms preprocess, 186.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 229.5ms\n","Speed: 4.5ms preprocess, 229.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 187.7ms\n","Speed: 4.1ms preprocess, 187.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 190.7ms\n","Speed: 4.1ms preprocess, 190.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 193.0ms\n","Speed: 4.0ms preprocess, 193.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 240.0ms\n","Speed: 4.2ms preprocess, 240.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 200.5ms\n","Speed: 3.8ms preprocess, 200.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 203.1ms\n","Speed: 3.9ms preprocess, 203.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 215.5ms\n","Speed: 6.2ms preprocess, 215.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 200.3ms\n","Speed: 12.7ms preprocess, 200.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 126.0ms\n","Speed: 3.8ms preprocess, 126.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 132.4ms\n","Speed: 3.9ms preprocess, 132.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 121.7ms\n","Speed: 4.1ms preprocess, 121.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 125.2ms\n","Speed: 3.8ms preprocess, 125.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 157.8ms\n","Speed: 3.9ms preprocess, 157.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 137.1ms\n","Speed: 5.0ms preprocess, 137.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 131.4ms\n","Speed: 3.8ms preprocess, 131.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 131.9ms\n","Speed: 3.8ms preprocess, 131.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 122.9ms\n","Speed: 4.6ms preprocess, 122.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 121.2ms\n","Speed: 4.8ms preprocess, 121.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 148.7ms\n","Speed: 3.8ms preprocess, 148.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 138.9ms\n","Speed: 4.3ms preprocess, 138.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 127.7ms\n","Speed: 4.1ms preprocess, 127.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 127.5ms\n","Speed: 4.0ms preprocess, 127.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 129.5ms\n","Speed: 3.9ms preprocess, 129.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 120.6ms\n","Speed: 3.9ms preprocess, 120.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 143.3ms\n","Speed: 4.1ms preprocess, 143.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 137.7ms\n","Speed: 3.9ms preprocess, 137.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 123.8ms\n","Speed: 4.0ms preprocess, 123.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 123.4ms\n","Speed: 4.2ms preprocess, 123.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 127.1ms\n","Speed: 7.2ms preprocess, 127.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 124.6ms\n","Speed: 3.6ms preprocess, 124.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 147.0ms\n","Speed: 3.8ms preprocess, 147.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 123.0ms\n","Speed: 4.1ms preprocess, 123.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 125.3ms\n","Speed: 4.0ms preprocess, 125.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 120.5ms\n","Speed: 5.1ms preprocess, 120.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 122.2ms\n","Speed: 4.1ms preprocess, 122.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 128.7ms\n","Speed: 3.7ms preprocess, 128.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 136.9ms\n","Speed: 5.3ms preprocess, 136.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 125.0ms\n","Speed: 4.3ms preprocess, 125.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 150.4ms\n","Speed: 5.2ms preprocess, 150.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 136.3ms\n","Speed: 4.8ms preprocess, 136.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 126.8ms\n","Speed: 4.5ms preprocess, 126.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 139.2ms\n","Speed: 4.1ms preprocess, 139.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 128.6ms\n","Speed: 5.3ms preprocess, 128.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 123.5ms\n","Speed: 4.6ms preprocess, 123.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 142.7ms\n","Speed: 4.9ms preprocess, 142.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 118.1ms\n","Speed: 4.0ms preprocess, 118.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 120.9ms\n","Speed: 4.9ms preprocess, 120.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 132.8ms\n","Speed: 4.7ms preprocess, 132.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 121.6ms\n","Speed: 7.4ms preprocess, 121.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 121.1ms\n","Speed: 4.6ms preprocess, 121.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 140.9ms\n","Speed: 5.4ms preprocess, 140.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 123.7ms\n","Speed: 4.9ms preprocess, 123.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 128.2ms\n","Speed: 4.6ms preprocess, 128.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 142.9ms\n","Speed: 5.2ms preprocess, 142.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 122.1ms\n","Speed: 6.8ms preprocess, 122.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 130.5ms\n","Speed: 4.0ms preprocess, 130.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 134.7ms\n","Speed: 3.9ms preprocess, 134.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 126.6ms\n","Speed: 4.0ms preprocess, 126.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 131.2ms\n","Speed: 3.7ms preprocess, 131.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 139.9ms\n","Speed: 4.4ms preprocess, 139.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 126.8ms\n","Speed: 4.1ms preprocess, 126.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 132.9ms\n","Speed: 4.4ms preprocess, 132.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 136.2ms\n","Speed: 4.1ms preprocess, 136.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 118.5ms\n","Speed: 8.6ms preprocess, 118.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 130.8ms\n","Speed: 4.5ms preprocess, 130.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 143.3ms\n","Speed: 8.4ms preprocess, 143.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 132.5ms\n","Speed: 3.9ms preprocess, 132.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 199.7ms\n","Speed: 4.3ms preprocess, 199.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 193.1ms\n","Speed: 4.7ms preprocess, 193.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 221.5ms\n","Speed: 4.1ms preprocess, 221.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 192.2ms\n","Speed: 4.1ms preprocess, 192.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 195.5ms\n","Speed: 3.9ms preprocess, 195.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 201.5ms\n","Speed: 4.0ms preprocess, 201.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 207.2ms\n","Speed: 9.1ms preprocess, 207.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 186.9ms\n","Speed: 3.9ms preprocess, 186.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 199.2ms\n","Speed: 6.2ms preprocess, 199.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 209.5ms\n","Speed: 4.5ms preprocess, 209.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 213.7ms\n","Speed: 4.5ms preprocess, 213.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 209.4ms\n","Speed: 4.0ms preprocess, 209.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 191.0ms\n","Speed: 6.6ms preprocess, 191.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 214.4ms\n","Speed: 7.6ms preprocess, 214.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 229.5ms\n","Speed: 7.0ms preprocess, 229.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 188.2ms\n","Speed: 5.9ms preprocess, 188.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 133.0ms\n","Speed: 8.6ms preprocess, 133.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 140.8ms\n","Speed: 4.2ms preprocess, 140.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 131.8ms\n","Speed: 4.1ms preprocess, 131.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 126.2ms\n","Speed: 4.3ms preprocess, 126.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 130.1ms\n","Speed: 4.3ms preprocess, 130.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 121.2ms\n","Speed: 4.7ms preprocess, 121.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 125.8ms\n","Speed: 4.8ms preprocess, 125.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 139.4ms\n","Speed: 5.2ms preprocess, 139.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 142.2ms\n","Speed: 6.5ms preprocess, 142.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 125.5ms\n","Speed: 6.0ms preprocess, 125.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 128.8ms\n","Speed: 3.9ms preprocess, 128.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 131.0ms\n","Speed: 3.9ms preprocess, 131.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 124.1ms\n","Speed: 6.4ms preprocess, 124.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 135.1ms\n","Speed: 4.3ms preprocess, 135.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 161.3ms\n","Speed: 8.9ms preprocess, 161.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 119.9ms\n","Speed: 4.1ms preprocess, 119.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 205.3ms\n","Speed: 4.4ms preprocess, 205.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 210.0ms\n","Speed: 6.1ms preprocess, 210.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 145.6ms\n","Speed: 4.1ms preprocess, 145.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 136.0ms\n","Speed: 9.1ms preprocess, 136.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 125.7ms\n","Speed: 4.1ms preprocess, 125.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 122.8ms\n","Speed: 4.5ms preprocess, 122.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 271.9ms\n","Speed: 5.3ms preprocess, 271.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 232.4ms\n","Speed: 6.3ms preprocess, 232.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 203.0ms\n","Speed: 6.4ms preprocess, 203.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 300.0ms\n","Speed: 6.1ms preprocess, 300.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 375.4ms\n","Speed: 4.0ms preprocess, 375.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 227.8ms\n","Speed: 3.8ms preprocess, 227.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 242.4ms\n","Speed: 4.1ms preprocess, 242.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 250.9ms\n","Speed: 10.5ms preprocess, 250.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 208.5ms\n","Speed: 3.9ms preprocess, 208.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 246.8ms\n","Speed: 4.3ms preprocess, 246.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 325.6ms\n","Speed: 10.9ms preprocess, 325.6ms inference, 9.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 311.3ms\n","Speed: 4.3ms preprocess, 311.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 311.4ms\n","Speed: 4.0ms preprocess, 311.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 239.3ms\n","Speed: 4.1ms preprocess, 239.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 259.9ms\n","Speed: 4.1ms preprocess, 259.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 322.4ms\n","Speed: 15.9ms preprocess, 322.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 201.7ms\n","Speed: 4.2ms preprocess, 201.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 446.9ms\n","Speed: 11.5ms preprocess, 446.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 389.5ms\n","Speed: 4.0ms preprocess, 389.5ms inference, 12.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 503.7ms\n","Speed: 4.1ms preprocess, 503.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 532.3ms\n","Speed: 4.1ms preprocess, 532.3ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 643.7ms\n","Speed: 11.0ms preprocess, 643.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 589.5ms\n","Speed: 9.3ms preprocess, 589.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 351.1ms\n","Speed: 4.9ms preprocess, 351.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 615.2ms\n","Speed: 23.1ms preprocess, 615.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 550.0ms\n","Speed: 7.1ms preprocess, 550.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 249.8ms\n","Speed: 5.1ms preprocess, 249.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 128.4ms\n","Speed: 4.0ms preprocess, 128.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 135.6ms\n","Speed: 4.8ms preprocess, 135.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 130.4ms\n","Speed: 4.6ms preprocess, 130.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 141.7ms\n","Speed: 4.0ms preprocess, 141.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 120.5ms\n","Speed: 3.8ms preprocess, 120.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 145.4ms\n","Speed: 3.9ms preprocess, 145.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 134.0ms\n","Speed: 4.2ms preprocess, 134.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 125.4ms\n","Speed: 3.9ms preprocess, 125.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 137.0ms\n","Speed: 3.9ms preprocess, 137.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 142.6ms\n","Speed: 3.9ms preprocess, 142.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 127.2ms\n","Speed: 4.8ms preprocess, 127.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 132.7ms\n","Speed: 3.8ms preprocess, 132.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 134.0ms\n","Speed: 4.0ms preprocess, 134.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 127.0ms\n","Speed: 3.8ms preprocess, 127.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 126.9ms\n","Speed: 4.1ms preprocess, 126.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 141.8ms\n","Speed: 5.0ms preprocess, 141.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 129.4ms\n","Speed: 4.1ms preprocess, 129.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 126.3ms\n","Speed: 3.9ms preprocess, 126.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 126.5ms\n","Speed: 3.8ms preprocess, 126.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 127.9ms\n","Speed: 11.5ms preprocess, 127.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 124.5ms\n","Speed: 3.9ms preprocess, 124.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 146.3ms\n","Speed: 7.5ms preprocess, 146.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 124.3ms\n","Speed: 4.3ms preprocess, 124.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 129.2ms\n","Speed: 4.1ms preprocess, 129.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 134.1ms\n","Speed: 4.1ms preprocess, 134.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 121.7ms\n","Speed: 4.3ms preprocess, 121.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 144.8ms\n","Speed: 4.1ms preprocess, 144.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 123.8ms\n","Speed: 5.1ms preprocess, 123.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 126.6ms\n","Speed: 4.0ms preprocess, 126.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 134.2ms\n","Speed: 4.1ms preprocess, 134.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 130.9ms\n","Speed: 4.1ms preprocess, 130.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 130.4ms\n","Speed: 4.3ms preprocess, 130.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 151.7ms\n","Speed: 3.9ms preprocess, 151.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 125.7ms\n","Speed: 3.9ms preprocess, 125.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 127.4ms\n","Speed: 3.9ms preprocess, 127.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 124.7ms\n","Speed: 4.0ms preprocess, 124.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 134.6ms\n","Speed: 4.3ms preprocess, 134.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 122.8ms\n","Speed: 4.1ms preprocess, 122.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 141.7ms\n","Speed: 4.1ms preprocess, 141.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 132.4ms\n","Speed: 4.8ms preprocess, 132.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 118.7ms\n","Speed: 6.1ms preprocess, 118.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 121.0ms\n","Speed: 3.9ms preprocess, 121.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 128.3ms\n","Speed: 4.7ms preprocess, 128.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 136.2ms\n","Speed: 4.1ms preprocess, 136.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 140.8ms\n","Speed: 8.9ms preprocess, 140.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 122.4ms\n","Speed: 3.9ms preprocess, 122.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 121.9ms\n","Speed: 5.2ms preprocess, 121.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 132.1ms\n","Speed: 4.7ms preprocess, 132.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 123.8ms\n","Speed: 4.5ms preprocess, 123.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 125.7ms\n","Speed: 6.1ms preprocess, 125.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 136.0ms\n","Speed: 3.9ms preprocess, 136.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 123.1ms\n","Speed: 4.2ms preprocess, 123.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 122.3ms\n","Speed: 4.3ms preprocess, 122.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 131.8ms\n","Speed: 4.0ms preprocess, 131.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 196.2ms\n","Speed: 5.7ms preprocess, 196.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 193.7ms\n","Speed: 6.4ms preprocess, 193.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 196.6ms\n","Speed: 4.2ms preprocess, 196.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 188.0ms\n","Speed: 5.9ms preprocess, 188.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 189.6ms\n","Speed: 4.0ms preprocess, 189.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 201.4ms\n","Speed: 4.0ms preprocess, 201.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 200.6ms\n","Speed: 4.2ms preprocess, 200.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 190.6ms\n","Speed: 5.8ms preprocess, 190.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 191.0ms\n","Speed: 4.1ms preprocess, 191.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n"]}]},{"cell_type":"code","source":["!pip install ipython"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ex-ltlRE-2V1","executionInfo":{"status":"ok","timestamp":1731509062978,"user_tz":-180,"elapsed":4376,"user":{"displayName":"BugBeauty","userId":"14397405117155400645"}},"outputId":"39777c96-34cd-4576-cd92-ae04732c2ae5"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (7.34.0)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython) (75.1.0)\n","Collecting jedi>=0.16 (from ipython)\n","  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython) (4.4.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython) (0.7.5)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython) (5.7.1)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython) (3.0.48)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython) (2.18.0)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython) (0.2.0)\n","Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython) (0.1.7)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython) (4.9.0)\n","Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython) (0.8.4)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython) (0.2.13)\n","Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: jedi\n","Successfully installed jedi-0.19.2\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","import cv2\n","import os\n","from ultralytics import YOLO\n","\n","# Google Drive'ı bağla\n","drive.mount('/content/gdrive')\n","\n","# Video klasörünün yolu\n","video_folder = '/content/gdrive/My Drive/ComputerVisionEngineer/ObjectDetectionYolov8/videos/'\n","\n","# Modelin yolu\n","model_path = '/content/gdrive/My Drive/ComputerVisionEngineer/ObjectDetectionYolov8/runs/detect/train82/weights/best.pt'\n","\n","# Modeli yükle\n","model = YOLO(model_path)\n","\n","threshold = 0.5\n","\n","# Klasördeki tüm video dosyalarını al\n","video_files = [f for f in os.listdir(video_folder) if f.endswith('.mp4')]\n","\n","# Her bir video dosyasını işleyelim\n","for video_file in video_files:\n","    video_path = os.path.join(video_folder, video_file)\n","    video_path_out = os.path.join(video_folder, f\"out_{video_file}\")\n","\n","    cap = cv2.VideoCapture(video_path)\n","    ret, frame = cap.read()\n","\n","    # Frame boyutlarını al\n","    H, W, _ = frame.shape\n","    out = cv2.VideoWriter(video_path_out, cv2.VideoWriter_fourcc(*'MP4V'), int(cap.get(cv2.CAP_PROP_FPS)), (W, H))\n","\n","    while ret:\n","        results = model(frame)[0]\n","\n","        # Sonuçları işleyin\n","        for result in results.boxes.data.tolist():\n","            x1, y1, x2, y2, score, class_id = result\n","\n","            if score > threshold:\n","                cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 4)\n","                cv2.putText(frame, results.names[int(class_id)].upper(), (int(x1), int(y1 - 10)),\n","                            cv2.FONT_HERSHEY_SIMPLEX, 1.3, (0, 255, 0), 3, cv2.LINE_AA)\n","\n","        out.write(frame)\n","        ret, frame = cap.read()\n","\n","    # Kaynakları serbest bırak\n","    cap.release()\n","    out.release()\n","\n","    print(f\"Processed video: {video_file}\")\n","\n","# Son olarak tüm pencereyi kapat\n","cv2.destroyAllWindows()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8d1_sXxq-shL","executionInfo":{"status":"ok","timestamp":1731510128084,"user_tz":-180,"elapsed":265736,"user":{"displayName":"BugBeauty","userId":"14397405117155400645"}},"outputId":"41f3904d-7dda-4300-a9c6-f34be3ab7a3c"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","\n","0: 352x640 1 alpaca, 133.7ms\n","Speed: 5.6ms preprocess, 133.7ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 109.2ms\n","Speed: 3.4ms preprocess, 109.2ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 111.8ms\n","Speed: 3.6ms preprocess, 111.8ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 108.4ms\n","Speed: 3.0ms preprocess, 108.4ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 110.4ms\n","Speed: 3.6ms preprocess, 110.4ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 121.4ms\n","Speed: 3.0ms preprocess, 121.4ms inference, 0.9ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 111.1ms\n","Speed: 2.6ms preprocess, 111.1ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 129.5ms\n","Speed: 3.1ms preprocess, 129.5ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 108.5ms\n","Speed: 2.7ms preprocess, 108.5ms inference, 0.9ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 111.7ms\n","Speed: 2.7ms preprocess, 111.7ms inference, 0.9ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 104.9ms\n","Speed: 2.7ms preprocess, 104.9ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 111.3ms\n","Speed: 2.7ms preprocess, 111.3ms inference, 0.9ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 111.8ms\n","Speed: 2.7ms preprocess, 111.8ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 117.5ms\n","Speed: 3.5ms preprocess, 117.5ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 118.6ms\n","Speed: 2.8ms preprocess, 118.6ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 125.3ms\n","Speed: 4.1ms preprocess, 125.3ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 108.2ms\n","Speed: 3.9ms preprocess, 108.2ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 108.3ms\n","Speed: 2.7ms preprocess, 108.3ms inference, 0.9ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 109.0ms\n","Speed: 2.7ms preprocess, 109.0ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 113.5ms\n","Speed: 4.5ms preprocess, 113.5ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 106.5ms\n","Speed: 3.6ms preprocess, 106.5ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 119.1ms\n","Speed: 3.0ms preprocess, 119.1ms inference, 0.9ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 171.2ms\n","Speed: 3.3ms preprocess, 171.2ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 170.3ms\n","Speed: 3.2ms preprocess, 170.3ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 170.2ms\n","Speed: 2.7ms preprocess, 170.2ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 167.5ms\n","Speed: 3.1ms preprocess, 167.5ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 173.7ms\n","Speed: 2.7ms preprocess, 173.7ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 173.2ms\n","Speed: 2.7ms preprocess, 173.2ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 165.6ms\n","Speed: 3.5ms preprocess, 165.6ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 166.7ms\n","Speed: 3.1ms preprocess, 166.7ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 170.5ms\n","Speed: 3.3ms preprocess, 170.5ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 169.5ms\n","Speed: 4.2ms preprocess, 169.5ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 179.8ms\n","Speed: 3.2ms preprocess, 179.8ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 2 alpacas, 174.1ms\n","Speed: 3.9ms preprocess, 174.1ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 2 alpacas, 168.4ms\n","Speed: 7.9ms preprocess, 168.4ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 173.4ms\n","Speed: 6.3ms preprocess, 173.4ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 172.9ms\n","Speed: 2.7ms preprocess, 172.9ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 167.7ms\n","Speed: 3.2ms preprocess, 167.7ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 196.8ms\n","Speed: 2.7ms preprocess, 196.8ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 175.3ms\n","Speed: 3.2ms preprocess, 175.3ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 175.2ms\n","Speed: 3.5ms preprocess, 175.2ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 178.7ms\n","Speed: 4.0ms preprocess, 178.7ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 171.3ms\n","Speed: 6.1ms preprocess, 171.3ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 201.0ms\n","Speed: 2.8ms preprocess, 201.0ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 184.6ms\n","Speed: 3.9ms preprocess, 184.6ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 150.9ms\n","Speed: 3.5ms preprocess, 150.9ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 110.2ms\n","Speed: 4.0ms preprocess, 110.2ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 115.5ms\n","Speed: 3.0ms preprocess, 115.5ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 111.3ms\n","Speed: 3.4ms preprocess, 111.3ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 110.3ms\n","Speed: 2.7ms preprocess, 110.3ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 140.9ms\n","Speed: 4.0ms preprocess, 140.9ms inference, 0.9ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 109.5ms\n","Speed: 2.6ms preprocess, 109.5ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 105.3ms\n","Speed: 2.4ms preprocess, 105.3ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 107.5ms\n","Speed: 2.6ms preprocess, 107.5ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 113.5ms\n","Speed: 2.6ms preprocess, 113.5ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 2 alpacas, 109.8ms\n","Speed: 3.7ms preprocess, 109.8ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 2 alpacas, 106.4ms\n","Speed: 2.7ms preprocess, 106.4ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 2 alpacas, 110.2ms\n","Speed: 2.7ms preprocess, 110.2ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 136.5ms\n","Speed: 2.7ms preprocess, 136.5ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 111.8ms\n","Speed: 3.4ms preprocess, 111.8ms inference, 0.9ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 107.8ms\n","Speed: 3.8ms preprocess, 107.8ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 106.2ms\n","Speed: 3.8ms preprocess, 106.2ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 107.3ms\n","Speed: 3.7ms preprocess, 107.3ms inference, 0.9ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 117.7ms\n","Speed: 3.8ms preprocess, 117.7ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 106.1ms\n","Speed: 2.9ms preprocess, 106.1ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 2 alpacas, 118.7ms\n","Speed: 3.0ms preprocess, 118.7ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 141.5ms\n","Speed: 4.2ms preprocess, 141.5ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 110.5ms\n","Speed: 3.0ms preprocess, 110.5ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 108.1ms\n","Speed: 2.7ms preprocess, 108.1ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 105.3ms\n","Speed: 3.2ms preprocess, 105.3ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 115.6ms\n","Speed: 4.0ms preprocess, 115.6ms inference, 0.9ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 108.8ms\n","Speed: 3.9ms preprocess, 108.8ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 106.3ms\n","Speed: 3.9ms preprocess, 106.3ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 2 alpacas, 129.1ms\n","Speed: 2.7ms preprocess, 129.1ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 114.1ms\n","Speed: 3.5ms preprocess, 114.1ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 2 alpacas, 117.4ms\n","Speed: 2.6ms preprocess, 117.4ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 113.6ms\n","Speed: 2.6ms preprocess, 113.6ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 111.6ms\n","Speed: 2.7ms preprocess, 111.6ms inference, 0.9ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 108.3ms\n","Speed: 2.9ms preprocess, 108.3ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 108.9ms\n","Speed: 3.4ms preprocess, 108.9ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 107.8ms\n","Speed: 2.7ms preprocess, 107.8ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 134.9ms\n","Speed: 4.4ms preprocess, 134.9ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 109.5ms\n","Speed: 2.8ms preprocess, 109.5ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 117.0ms\n","Speed: 2.7ms preprocess, 117.0ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 105.8ms\n","Speed: 3.6ms preprocess, 105.8ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 109.7ms\n","Speed: 3.7ms preprocess, 109.7ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 112.2ms\n","Speed: 2.7ms preprocess, 112.2ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 111.4ms\n","Speed: 2.7ms preprocess, 111.4ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 112.1ms\n","Speed: 2.7ms preprocess, 112.1ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 139.2ms\n","Speed: 2.7ms preprocess, 139.2ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 104.9ms\n","Speed: 3.9ms preprocess, 104.9ms inference, 0.9ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 117.3ms\n","Speed: 3.9ms preprocess, 117.3ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 104.7ms\n","Speed: 3.5ms preprocess, 104.7ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 110.8ms\n","Speed: 3.1ms preprocess, 110.8ms inference, 0.9ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 106.7ms\n","Speed: 3.3ms preprocess, 106.7ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 104.4ms\n","Speed: 2.6ms preprocess, 104.4ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 117.1ms\n","Speed: 2.7ms preprocess, 117.1ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 2 alpacas, 132.6ms\n","Speed: 4.5ms preprocess, 132.6ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 105.8ms\n","Speed: 3.3ms preprocess, 105.8ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 121.0ms\n","Speed: 3.7ms preprocess, 121.0ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 110.9ms\n","Speed: 3.1ms preprocess, 110.9ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 116.7ms\n","Speed: 2.7ms preprocess, 116.7ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 107.9ms\n","Speed: 3.4ms preprocess, 107.9ms inference, 0.9ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 105.2ms\n","Speed: 3.5ms preprocess, 105.2ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 122.8ms\n","Speed: 2.6ms preprocess, 122.8ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 117.0ms\n","Speed: 2.8ms preprocess, 117.0ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 110.2ms\n","Speed: 2.7ms preprocess, 110.2ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 117.6ms\n","Speed: 2.7ms preprocess, 117.6ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 2 alpacas, 106.5ms\n","Speed: 2.7ms preprocess, 106.5ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 108.5ms\n","Speed: 2.7ms preprocess, 108.5ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 112.0ms\n","Speed: 2.7ms preprocess, 112.0ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 107.8ms\n","Speed: 2.7ms preprocess, 107.8ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 129.2ms\n","Speed: 2.8ms preprocess, 129.2ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 116.6ms\n","Speed: 3.0ms preprocess, 116.6ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 106.4ms\n","Speed: 3.8ms preprocess, 106.4ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 118.2ms\n","Speed: 2.7ms preprocess, 118.2ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 110.3ms\n","Speed: 2.7ms preprocess, 110.3ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 130.4ms\n","Speed: 2.9ms preprocess, 130.4ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 110.3ms\n","Speed: 3.7ms preprocess, 110.3ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 109.9ms\n","Speed: 3.0ms preprocess, 109.9ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 131.3ms\n","Speed: 3.9ms preprocess, 131.3ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 110.5ms\n","Speed: 2.3ms preprocess, 110.5ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 105.9ms\n","Speed: 2.6ms preprocess, 105.9ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 181.9ms\n","Speed: 3.5ms preprocess, 181.9ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 180.2ms\n","Speed: 2.7ms preprocess, 180.2ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 170.9ms\n","Speed: 2.9ms preprocess, 170.9ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 177.1ms\n","Speed: 3.0ms preprocess, 177.1ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 171.4ms\n","Speed: 2.8ms preprocess, 171.4ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 173.0ms\n","Speed: 2.7ms preprocess, 173.0ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 164.9ms\n","Speed: 2.8ms preprocess, 164.9ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 175.6ms\n","Speed: 2.9ms preprocess, 175.6ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 195.2ms\n","Speed: 2.7ms preprocess, 195.2ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 179.6ms\n","Speed: 3.0ms preprocess, 179.6ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 168.2ms\n","Speed: 2.6ms preprocess, 168.2ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 172.5ms\n","Speed: 2.7ms preprocess, 172.5ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 173.4ms\n","Speed: 2.7ms preprocess, 173.4ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 170.3ms\n","Speed: 2.8ms preprocess, 170.3ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 164.7ms\n","Speed: 2.7ms preprocess, 164.7ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 164.9ms\n","Speed: 2.8ms preprocess, 164.9ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 185.6ms\n","Speed: 3.0ms preprocess, 185.6ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 165.1ms\n","Speed: 3.9ms preprocess, 165.1ms inference, 1.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 184.5ms\n","Speed: 2.8ms preprocess, 184.5ms inference, 6.9ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 200.1ms\n","Speed: 3.7ms preprocess, 200.1ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 179.7ms\n","Speed: 3.5ms preprocess, 179.7ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 169.0ms\n","Speed: 2.7ms preprocess, 169.0ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 176.9ms\n","Speed: 2.8ms preprocess, 176.9ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 110.7ms\n","Speed: 2.8ms preprocess, 110.7ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 123.2ms\n","Speed: 4.0ms preprocess, 123.2ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 110.4ms\n","Speed: 2.7ms preprocess, 110.4ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 110.9ms\n","Speed: 2.8ms preprocess, 110.9ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 106.4ms\n","Speed: 2.6ms preprocess, 106.4ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 108.3ms\n","Speed: 2.6ms preprocess, 108.3ms inference, 0.9ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 110.8ms\n","Speed: 2.7ms preprocess, 110.8ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 125.1ms\n","Speed: 2.6ms preprocess, 125.1ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 111.3ms\n","Speed: 2.6ms preprocess, 111.3ms inference, 0.9ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 130.3ms\n","Speed: 2.7ms preprocess, 130.3ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 120.8ms\n","Speed: 2.8ms preprocess, 120.8ms inference, 0.9ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 105.9ms\n","Speed: 3.8ms preprocess, 105.9ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 106.3ms\n","Speed: 3.1ms preprocess, 106.3ms inference, 0.9ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 108.2ms\n","Speed: 3.6ms preprocess, 108.2ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 111.5ms\n","Speed: 2.9ms preprocess, 111.5ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 127.0ms\n","Speed: 3.1ms preprocess, 127.0ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 113.4ms\n","Speed: 4.1ms preprocess, 113.4ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 127.6ms\n","Speed: 3.8ms preprocess, 127.6ms inference, 0.9ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 107.9ms\n","Speed: 4.0ms preprocess, 107.9ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 112.5ms\n","Speed: 2.6ms preprocess, 112.5ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 107.1ms\n","Speed: 2.6ms preprocess, 107.1ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 107.3ms\n","Speed: 3.6ms preprocess, 107.3ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 107.4ms\n","Speed: 2.7ms preprocess, 107.4ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 123.5ms\n","Speed: 2.5ms preprocess, 123.5ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 112.4ms\n","Speed: 2.6ms preprocess, 112.4ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 143.0ms\n","Speed: 3.0ms preprocess, 143.0ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 111.3ms\n","Speed: 2.7ms preprocess, 111.3ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 106.5ms\n","Speed: 3.8ms preprocess, 106.5ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 113.3ms\n","Speed: 2.7ms preprocess, 113.3ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 110.3ms\n","Speed: 2.7ms preprocess, 110.3ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 113.3ms\n","Speed: 2.7ms preprocess, 113.3ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 120.8ms\n","Speed: 3.8ms preprocess, 120.8ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 117.9ms\n","Speed: 2.9ms preprocess, 117.9ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 127.0ms\n","Speed: 2.7ms preprocess, 127.0ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 108.8ms\n","Speed: 2.8ms preprocess, 108.8ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 107.3ms\n","Speed: 3.9ms preprocess, 107.3ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 107.9ms\n","Speed: 3.5ms preprocess, 107.9ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 119.8ms\n","Speed: 2.6ms preprocess, 119.8ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 107.0ms\n","Speed: 2.6ms preprocess, 107.0ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 121.2ms\n","Speed: 2.6ms preprocess, 121.2ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 129.9ms\n","Speed: 2.7ms preprocess, 129.9ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 113.9ms\n","Speed: 3.5ms preprocess, 113.9ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 106.7ms\n","Speed: 3.0ms preprocess, 106.7ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 110.6ms\n","Speed: 2.8ms preprocess, 110.6ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 109.9ms\n","Speed: 2.6ms preprocess, 109.9ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 110.8ms\n","Speed: 2.7ms preprocess, 110.8ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 107.5ms\n","Speed: 2.7ms preprocess, 107.5ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 124.9ms\n","Speed: 2.7ms preprocess, 124.9ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 132.8ms\n","Speed: 2.7ms preprocess, 132.8ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 115.3ms\n","Speed: 4.3ms preprocess, 115.3ms inference, 0.9ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 111.0ms\n","Speed: 2.7ms preprocess, 111.0ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 109.4ms\n","Speed: 2.8ms preprocess, 109.4ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 112.8ms\n","Speed: 2.6ms preprocess, 112.8ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 111.1ms\n","Speed: 2.8ms preprocess, 111.1ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 110.5ms\n","Speed: 4.6ms preprocess, 110.5ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 121.4ms\n","Speed: 3.6ms preprocess, 121.4ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 132.9ms\n","Speed: 3.4ms preprocess, 132.9ms inference, 0.9ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 109.3ms\n","Speed: 4.4ms preprocess, 109.3ms inference, 0.9ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 106.0ms\n","Speed: 3.4ms preprocess, 106.0ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 106.5ms\n","Speed: 3.9ms preprocess, 106.5ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 108.9ms\n","Speed: 3.0ms preprocess, 108.9ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 110.6ms\n","Speed: 2.9ms preprocess, 110.6ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 105.3ms\n","Speed: 2.7ms preprocess, 105.3ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 120.4ms\n","Speed: 2.7ms preprocess, 120.4ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 137.7ms\n","Speed: 2.5ms preprocess, 137.7ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 110.0ms\n","Speed: 2.7ms preprocess, 110.0ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 108.7ms\n","Speed: 2.6ms preprocess, 108.7ms inference, 0.9ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 111.7ms\n","Speed: 2.7ms preprocess, 111.7ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 107.6ms\n","Speed: 2.9ms preprocess, 107.6ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 108.2ms\n","Speed: 2.9ms preprocess, 108.2ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 107.8ms\n","Speed: 2.6ms preprocess, 107.8ms inference, 0.9ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 131.1ms\n","Speed: 2.6ms preprocess, 131.1ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 136.0ms\n","Speed: 2.8ms preprocess, 136.0ms inference, 0.9ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 108.9ms\n","Speed: 2.7ms preprocess, 108.9ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 113.0ms\n","Speed: 2.6ms preprocess, 113.0ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 106.9ms\n","Speed: 2.7ms preprocess, 106.9ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 111.9ms\n","Speed: 2.6ms preprocess, 111.9ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 122.5ms\n","Speed: 2.7ms preprocess, 122.5ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 195.8ms\n","Speed: 6.8ms preprocess, 195.8ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 179.2ms\n","Speed: 5.3ms preprocess, 179.2ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 171.1ms\n","Speed: 2.7ms preprocess, 171.1ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 166.0ms\n","Speed: 3.3ms preprocess, 166.0ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 171.5ms\n","Speed: 2.7ms preprocess, 171.5ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 175.1ms\n","Speed: 5.2ms preprocess, 175.1ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 185.7ms\n","Speed: 2.9ms preprocess, 185.7ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 175.1ms\n","Speed: 3.1ms preprocess, 175.1ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 179.5ms\n","Speed: 2.8ms preprocess, 179.5ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 167.5ms\n","Speed: 2.8ms preprocess, 167.5ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 167.8ms\n","Speed: 3.6ms preprocess, 167.8ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 202.9ms\n","Speed: 2.8ms preprocess, 202.9ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 168.0ms\n","Speed: 2.8ms preprocess, 168.0ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 163.3ms\n","Speed: 2.9ms preprocess, 163.3ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 162.4ms\n","Speed: 3.0ms preprocess, 162.4ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 177.8ms\n","Speed: 3.7ms preprocess, 177.8ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 183.2ms\n","Speed: 3.8ms preprocess, 183.2ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 181.7ms\n","Speed: 3.1ms preprocess, 181.7ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 183.7ms\n","Speed: 4.5ms preprocess, 183.7ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 184.7ms\n","Speed: 4.1ms preprocess, 184.7ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 173.2ms\n","Speed: 2.7ms preprocess, 173.2ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 195.4ms\n","Speed: 2.6ms preprocess, 195.4ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 137.2ms\n","Speed: 3.1ms preprocess, 137.2ms inference, 0.9ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 106.7ms\n","Speed: 3.0ms preprocess, 106.7ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 108.4ms\n","Speed: 4.7ms preprocess, 108.4ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 106.8ms\n","Speed: 2.7ms preprocess, 106.8ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 113.8ms\n","Speed: 4.2ms preprocess, 113.8ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 107.0ms\n","Speed: 2.6ms preprocess, 107.0ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 118.1ms\n","Speed: 2.8ms preprocess, 118.1ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 121.9ms\n","Speed: 3.0ms preprocess, 121.9ms inference, 0.9ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 121.9ms\n","Speed: 2.6ms preprocess, 121.9ms inference, 0.9ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 107.7ms\n","Speed: 2.7ms preprocess, 107.7ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 111.7ms\n","Speed: 2.7ms preprocess, 111.7ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 106.5ms\n","Speed: 2.7ms preprocess, 106.5ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 121.2ms\n","Speed: 2.6ms preprocess, 121.2ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 109.1ms\n","Speed: 2.6ms preprocess, 109.1ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 119.2ms\n","Speed: 2.7ms preprocess, 119.2ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 122.0ms\n","Speed: 4.1ms preprocess, 122.0ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 115.1ms\n","Speed: 3.1ms preprocess, 115.1ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 110.2ms\n","Speed: 2.8ms preprocess, 110.2ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 104.7ms\n","Speed: 3.6ms preprocess, 104.7ms inference, 0.9ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 108.1ms\n","Speed: 3.0ms preprocess, 108.1ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 105.7ms\n","Speed: 2.7ms preprocess, 105.7ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 111.9ms\n","Speed: 2.7ms preprocess, 111.9ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 124.6ms\n","Speed: 3.6ms preprocess, 124.6ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 122.6ms\n","Speed: 3.7ms preprocess, 122.6ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 109.7ms\n","Speed: 4.1ms preprocess, 109.7ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 117.2ms\n","Speed: 3.3ms preprocess, 117.2ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 110.4ms\n","Speed: 2.7ms preprocess, 110.4ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 108.3ms\n","Speed: 2.7ms preprocess, 108.3ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 114.0ms\n","Speed: 2.8ms preprocess, 114.0ms inference, 0.9ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 108.1ms\n","Speed: 2.7ms preprocess, 108.1ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 132.5ms\n","Speed: 2.7ms preprocess, 132.5ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 111.3ms\n","Speed: 3.5ms preprocess, 111.3ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 112.1ms\n","Speed: 3.3ms preprocess, 112.1ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 117.7ms\n","Speed: 3.5ms preprocess, 117.7ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 2 alpacas, 105.2ms\n","Speed: 2.9ms preprocess, 105.2ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 2 alpacas, 110.2ms\n","Speed: 3.4ms preprocess, 110.2ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 109.3ms\n","Speed: 2.4ms preprocess, 109.3ms inference, 0.9ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 111.4ms\n","Speed: 2.8ms preprocess, 111.4ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 131.9ms\n","Speed: 7.2ms preprocess, 131.9ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 107.4ms\n","Speed: 3.8ms preprocess, 107.4ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 113.7ms\n","Speed: 2.9ms preprocess, 113.7ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 119.6ms\n","Speed: 3.0ms preprocess, 119.6ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 109.6ms\n","Speed: 2.9ms preprocess, 109.6ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 109.3ms\n","Speed: 3.6ms preprocess, 109.3ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 107.2ms\n","Speed: 2.8ms preprocess, 107.2ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 119.2ms\n","Speed: 2.7ms preprocess, 119.2ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 133.8ms\n","Speed: 3.7ms preprocess, 133.8ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 110.3ms\n","Speed: 2.7ms preprocess, 110.3ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 106.7ms\n","Speed: 4.2ms preprocess, 106.7ms inference, 0.9ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 2 alpacas, 125.5ms\n","Speed: 3.3ms preprocess, 125.5ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 110.4ms\n","Speed: 3.1ms preprocess, 110.4ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 107.9ms\n","Speed: 2.7ms preprocess, 107.9ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 116.3ms\n","Speed: 2.6ms preprocess, 116.3ms inference, 0.9ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 123.7ms\n","Speed: 3.5ms preprocess, 123.7ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 117.5ms\n","Speed: 3.8ms preprocess, 117.5ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 113.8ms\n","Speed: 2.8ms preprocess, 113.8ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 105.9ms\n","Speed: 2.7ms preprocess, 105.9ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 116.4ms\n","Speed: 3.7ms preprocess, 116.4ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 107.4ms\n","Speed: 3.0ms preprocess, 107.4ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 111.6ms\n","Speed: 3.4ms preprocess, 111.6ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 106.2ms\n","Speed: 2.6ms preprocess, 106.2ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 134.0ms\n","Speed: 2.7ms preprocess, 134.0ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 112.9ms\n","Speed: 2.7ms preprocess, 112.9ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 108.6ms\n","Speed: 2.8ms preprocess, 108.6ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 110.0ms\n","Speed: 3.1ms preprocess, 110.0ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 116.4ms\n","Speed: 2.4ms preprocess, 116.4ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 109.7ms\n","Speed: 3.3ms preprocess, 109.7ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 110.1ms\n","Speed: 2.7ms preprocess, 110.1ms inference, 0.9ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 109.6ms\n","Speed: 3.2ms preprocess, 109.6ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 130.6ms\n","Speed: 3.3ms preprocess, 130.6ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 108.6ms\n","Speed: 3.7ms preprocess, 108.6ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 105.2ms\n","Speed: 3.8ms preprocess, 105.2ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 108.1ms\n","Speed: 2.6ms preprocess, 108.1ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 118.7ms\n","Speed: 2.6ms preprocess, 118.7ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 112.7ms\n","Speed: 2.6ms preprocess, 112.7ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 105.7ms\n","Speed: 3.6ms preprocess, 105.7ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 109.2ms\n","Speed: 2.8ms preprocess, 109.2ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 140.0ms\n","Speed: 2.6ms preprocess, 140.0ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 160.1ms\n","Speed: 2.7ms preprocess, 160.1ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 173.2ms\n","Speed: 2.8ms preprocess, 173.2ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 177.8ms\n","Speed: 2.8ms preprocess, 177.8ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 177.7ms\n","Speed: 2.9ms preprocess, 177.7ms inference, 1.9ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 207.6ms\n","Speed: 3.1ms preprocess, 207.6ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 2 alpacas, 166.4ms\n","Speed: 4.6ms preprocess, 166.4ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 178.3ms\n","Speed: 2.7ms preprocess, 178.3ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 2 alpacas, 178.8ms\n","Speed: 2.7ms preprocess, 178.8ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 2 alpacas, 178.0ms\n","Speed: 2.8ms preprocess, 178.0ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 2 alpacas, 176.4ms\n","Speed: 3.9ms preprocess, 176.4ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 165.5ms\n","Speed: 3.4ms preprocess, 165.5ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 165.0ms\n","Speed: 2.8ms preprocess, 165.0ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 183.6ms\n","Speed: 2.7ms preprocess, 183.6ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 166.5ms\n","Speed: 2.8ms preprocess, 166.5ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 188.5ms\n","Speed: 2.9ms preprocess, 188.5ms inference, 2.3ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 185.2ms\n","Speed: 2.7ms preprocess, 185.2ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 173.0ms\n","Speed: 4.0ms preprocess, 173.0ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 174.2ms\n","Speed: 4.6ms preprocess, 174.2ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 187.8ms\n","Speed: 2.7ms preprocess, 187.8ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 177.1ms\n","Speed: 2.7ms preprocess, 177.1ms inference, 1.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 183.2ms\n","Speed: 4.6ms preprocess, 183.2ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 169.0ms\n","Speed: 2.7ms preprocess, 169.0ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 166.1ms\n","Speed: 2.8ms preprocess, 166.1ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 113.0ms\n","Speed: 3.1ms preprocess, 113.0ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 119.2ms\n","Speed: 2.6ms preprocess, 119.2ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 110.0ms\n","Speed: 3.5ms preprocess, 110.0ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 136.4ms\n","Speed: 6.9ms preprocess, 136.4ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 109.9ms\n","Speed: 3.0ms preprocess, 109.9ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 108.9ms\n","Speed: 2.6ms preprocess, 108.9ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 109.5ms\n","Speed: 2.7ms preprocess, 109.5ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 113.9ms\n","Speed: 2.9ms preprocess, 113.9ms inference, 0.9ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 107.7ms\n","Speed: 2.7ms preprocess, 107.7ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 119.3ms\n","Speed: 2.8ms preprocess, 119.3ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 113.0ms\n","Speed: 3.5ms preprocess, 113.0ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 130.5ms\n","Speed: 2.8ms preprocess, 130.5ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 114.8ms\n","Speed: 3.0ms preprocess, 114.8ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 106.5ms\n","Speed: 3.4ms preprocess, 106.5ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 113.3ms\n","Speed: 3.1ms preprocess, 113.3ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 106.4ms\n","Speed: 3.4ms preprocess, 106.4ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 109.3ms\n","Speed: 2.8ms preprocess, 109.3ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 117.2ms\n","Speed: 4.1ms preprocess, 117.2ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 123.6ms\n","Speed: 2.7ms preprocess, 123.6ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 118.6ms\n","Speed: 3.4ms preprocess, 118.6ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 109.3ms\n","Speed: 3.0ms preprocess, 109.3ms inference, 0.9ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 106.7ms\n","Speed: 2.9ms preprocess, 106.7ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 113.0ms\n","Speed: 2.6ms preprocess, 113.0ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 109.1ms\n","Speed: 2.9ms preprocess, 109.1ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 109.4ms\n","Speed: 3.3ms preprocess, 109.4ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 120.8ms\n","Speed: 2.8ms preprocess, 120.8ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 137.6ms\n","Speed: 4.3ms preprocess, 137.6ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 111.7ms\n","Speed: 3.6ms preprocess, 111.7ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 109.8ms\n","Speed: 2.7ms preprocess, 109.8ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 107.2ms\n","Speed: 3.9ms preprocess, 107.2ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 107.8ms\n","Speed: 2.7ms preprocess, 107.8ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 106.3ms\n","Speed: 3.2ms preprocess, 106.3ms inference, 0.9ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 104.7ms\n","Speed: 2.7ms preprocess, 104.7ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 123.2ms\n","Speed: 2.7ms preprocess, 123.2ms inference, 0.9ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 132.1ms\n","Speed: 2.6ms preprocess, 132.1ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 107.8ms\n","Speed: 2.7ms preprocess, 107.8ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 116.5ms\n","Speed: 3.1ms preprocess, 116.5ms inference, 0.9ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 111.0ms\n","Speed: 3.2ms preprocess, 111.0ms inference, 0.9ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 108.0ms\n","Speed: 4.7ms preprocess, 108.0ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 108.9ms\n","Speed: 2.5ms preprocess, 108.9ms inference, 0.9ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 110.9ms\n","Speed: 2.8ms preprocess, 110.9ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 122.3ms\n","Speed: 2.7ms preprocess, 122.3ms inference, 0.9ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 127.6ms\n","Speed: 2.9ms preprocess, 127.6ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 110.9ms\n","Speed: 2.6ms preprocess, 110.9ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 106.2ms\n","Speed: 2.7ms preprocess, 106.2ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 107.5ms\n","Speed: 2.6ms preprocess, 107.5ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 109.1ms\n","Speed: 2.6ms preprocess, 109.1ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 112.9ms\n","Speed: 2.7ms preprocess, 112.9ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 112.6ms\n","Speed: 2.6ms preprocess, 112.6ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 132.6ms\n","Speed: 2.8ms preprocess, 132.6ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 133.7ms\n","Speed: 2.7ms preprocess, 133.7ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 107.1ms\n","Speed: 2.6ms preprocess, 107.1ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 107.1ms\n","Speed: 3.6ms preprocess, 107.1ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 108.6ms\n","Speed: 3.5ms preprocess, 108.6ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 109.5ms\n","Speed: 3.7ms preprocess, 109.5ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 106.9ms\n","Speed: 4.2ms preprocess, 106.9ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 110.4ms\n","Speed: 3.0ms preprocess, 110.4ms inference, 0.9ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 139.1ms\n","Speed: 2.8ms preprocess, 139.1ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 117.3ms\n","Speed: 3.0ms preprocess, 117.3ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 106.6ms\n","Speed: 2.7ms preprocess, 106.6ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 108.9ms\n","Speed: 2.7ms preprocess, 108.9ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 110.0ms\n","Speed: 2.8ms preprocess, 110.0ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 109.1ms\n","Speed: 2.8ms preprocess, 109.1ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 113.4ms\n","Speed: 2.7ms preprocess, 113.4ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 113.0ms\n","Speed: 2.9ms preprocess, 113.0ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 143.1ms\n","Speed: 2.7ms preprocess, 143.1ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 113.2ms\n","Speed: 2.7ms preprocess, 113.2ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 112.9ms\n","Speed: 3.4ms preprocess, 112.9ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 112.6ms\n","Speed: 2.7ms preprocess, 112.6ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 106.8ms\n","Speed: 2.7ms preprocess, 106.8ms inference, 0.9ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 116.4ms\n","Speed: 2.6ms preprocess, 116.4ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 109.4ms\n","Speed: 6.2ms preprocess, 109.4ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 113.1ms\n","Speed: 2.6ms preprocess, 113.1ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 159.0ms\n","Speed: 2.9ms preprocess, 159.0ms inference, 0.9ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 113.5ms\n","Speed: 2.9ms preprocess, 113.5ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 106.7ms\n","Speed: 2.7ms preprocess, 106.7ms inference, 0.9ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 113.0ms\n","Speed: 2.7ms preprocess, 113.0ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 158.3ms\n","Speed: 2.6ms preprocess, 158.3ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 170.6ms\n","Speed: 2.7ms preprocess, 170.6ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 180.4ms\n","Speed: 3.0ms preprocess, 180.4ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 178.7ms\n","Speed: 3.0ms preprocess, 178.7ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 164.5ms\n","Speed: 2.8ms preprocess, 164.5ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 166.3ms\n","Speed: 2.7ms preprocess, 166.3ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 162.2ms\n","Speed: 2.8ms preprocess, 162.2ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 178.3ms\n","Speed: 2.7ms preprocess, 178.3ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 197.6ms\n","Speed: 2.7ms preprocess, 197.6ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 169.5ms\n","Speed: 4.8ms preprocess, 169.5ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 168.7ms\n","Speed: 3.0ms preprocess, 168.7ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 175.0ms\n","Speed: 3.2ms preprocess, 175.0ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 167.0ms\n","Speed: 3.3ms preprocess, 167.0ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 189.1ms\n","Speed: 4.5ms preprocess, 189.1ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 173.2ms\n","Speed: 3.9ms preprocess, 173.2ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 173.1ms\n","Speed: 5.8ms preprocess, 173.1ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 169.2ms\n","Speed: 2.8ms preprocess, 169.2ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 176.1ms\n","Speed: 3.3ms preprocess, 176.1ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 171.9ms\n","Speed: 10.1ms preprocess, 171.9ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 192.5ms\n","Speed: 2.9ms preprocess, 192.5ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 186.9ms\n","Speed: 2.8ms preprocess, 186.9ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 186.7ms\n","Speed: 5.3ms preprocess, 186.7ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 171.2ms\n","Speed: 2.7ms preprocess, 171.2ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 170.4ms\n","Speed: 2.8ms preprocess, 170.4ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 111.5ms\n","Speed: 2.7ms preprocess, 111.5ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 120.6ms\n","Speed: 3.6ms preprocess, 120.6ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 108.7ms\n","Speed: 2.7ms preprocess, 108.7ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 111.4ms\n","Speed: 3.4ms preprocess, 111.4ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 106.4ms\n","Speed: 2.6ms preprocess, 106.4ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 111.6ms\n","Speed: 3.1ms preprocess, 111.6ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 111.6ms\n","Speed: 2.7ms preprocess, 111.6ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 132.0ms\n","Speed: 2.6ms preprocess, 132.0ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 110.7ms\n","Speed: 2.8ms preprocess, 110.7ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 116.6ms\n","Speed: 3.7ms preprocess, 116.6ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 105.7ms\n","Speed: 2.7ms preprocess, 105.7ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 108.2ms\n","Speed: 2.6ms preprocess, 108.2ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 107.2ms\n","Speed: 3.5ms preprocess, 107.2ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 106.5ms\n","Speed: 3.2ms preprocess, 106.5ms inference, 0.9ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 115.4ms\n","Speed: 3.4ms preprocess, 115.4ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 120.6ms\n","Speed: 3.0ms preprocess, 120.6ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 109.9ms\n","Speed: 2.6ms preprocess, 109.9ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 105.8ms\n","Speed: 2.8ms preprocess, 105.8ms inference, 0.9ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 119.2ms\n","Speed: 4.8ms preprocess, 119.2ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 108.5ms\n","Speed: 3.0ms preprocess, 108.5ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 113.1ms\n","Speed: 3.4ms preprocess, 113.1ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 108.2ms\n","Speed: 2.7ms preprocess, 108.2ms inference, 0.9ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 123.3ms\n","Speed: 5.3ms preprocess, 123.3ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 126.3ms\n","Speed: 3.0ms preprocess, 126.3ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 110.7ms\n","Speed: 3.1ms preprocess, 110.7ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 107.2ms\n","Speed: 2.7ms preprocess, 107.2ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 118.2ms\n","Speed: 2.8ms preprocess, 118.2ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 113.0ms\n","Speed: 3.3ms preprocess, 113.0ms inference, 0.9ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 109.6ms\n","Speed: 2.6ms preprocess, 109.6ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 110.4ms\n","Speed: 2.7ms preprocess, 110.4ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 127.7ms\n","Speed: 2.7ms preprocess, 127.7ms inference, 0.9ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 106.4ms\n","Speed: 3.6ms preprocess, 106.4ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 105.9ms\n","Speed: 2.8ms preprocess, 105.9ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 105.7ms\n","Speed: 3.0ms preprocess, 105.7ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 118.6ms\n","Speed: 2.9ms preprocess, 118.6ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 114.2ms\n","Speed: 2.8ms preprocess, 114.2ms inference, 0.9ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 105.2ms\n","Speed: 3.2ms preprocess, 105.2ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 105.7ms\n","Speed: 3.3ms preprocess, 105.7ms inference, 0.9ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 130.6ms\n","Speed: 3.5ms preprocess, 130.6ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 109.6ms\n","Speed: 3.2ms preprocess, 109.6ms inference, 0.9ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 106.7ms\n","Speed: 3.4ms preprocess, 106.7ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 112.6ms\n","Speed: 2.6ms preprocess, 112.6ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 124.7ms\n","Speed: 2.7ms preprocess, 124.7ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 111.6ms\n","Speed: 2.8ms preprocess, 111.6ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 109.5ms\n","Speed: 2.6ms preprocess, 109.5ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 120.8ms\n","Speed: 2.7ms preprocess, 120.8ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 136.7ms\n","Speed: 2.8ms preprocess, 136.7ms inference, 0.9ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 112.4ms\n","Speed: 3.3ms preprocess, 112.4ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 113.7ms\n","Speed: 3.4ms preprocess, 113.7ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 106.6ms\n","Speed: 2.6ms preprocess, 106.6ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 120.6ms\n","Speed: 2.8ms preprocess, 120.6ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 111.6ms\n","Speed: 2.7ms preprocess, 111.6ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 110.2ms\n","Speed: 2.8ms preprocess, 110.2ms inference, 0.9ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 129.2ms\n","Speed: 2.8ms preprocess, 129.2ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 126.0ms\n","Speed: 2.8ms preprocess, 126.0ms inference, 0.9ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 115.5ms\n","Speed: 2.7ms preprocess, 115.5ms inference, 0.9ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 108.3ms\n","Speed: 2.7ms preprocess, 108.3ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 111.9ms\n","Speed: 2.7ms preprocess, 111.9ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 129.0ms\n","Speed: 2.7ms preprocess, 129.0ms inference, 0.9ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 117.8ms\n","Speed: 3.2ms preprocess, 117.8ms inference, 0.9ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 116.1ms\n","Speed: 3.2ms preprocess, 116.1ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 133.3ms\n","Speed: 5.0ms preprocess, 133.3ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 111.7ms\n","Speed: 2.8ms preprocess, 111.7ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 113.1ms\n","Speed: 2.7ms preprocess, 113.1ms inference, 0.9ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 110.4ms\n","Speed: 2.6ms preprocess, 110.4ms inference, 0.9ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 2 alpacas, 130.3ms\n","Speed: 4.4ms preprocess, 130.3ms inference, 0.9ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 2 alpacas, 109.0ms\n","Speed: 3.3ms preprocess, 109.0ms inference, 0.9ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 2 alpacas, 118.6ms\n","Speed: 2.7ms preprocess, 118.6ms inference, 0.9ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 134.4ms\n","Speed: 2.8ms preprocess, 134.4ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 119.9ms\n","Speed: 2.9ms preprocess, 119.9ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 111.0ms\n","Speed: 2.7ms preprocess, 111.0ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 112.9ms\n","Speed: 2.8ms preprocess, 112.9ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 109.5ms\n","Speed: 2.8ms preprocess, 109.5ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 126.4ms\n","Speed: 2.8ms preprocess, 126.4ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 117.1ms\n","Speed: 2.7ms preprocess, 117.1ms inference, 0.9ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 111.2ms\n","Speed: 3.2ms preprocess, 111.2ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 171.0ms\n","Speed: 2.7ms preprocess, 171.0ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 171.9ms\n","Speed: 2.9ms preprocess, 171.9ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 173.9ms\n","Speed: 2.7ms preprocess, 173.9ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 181.4ms\n","Speed: 3.6ms preprocess, 181.4ms inference, 6.2ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 177.8ms\n","Speed: 3.4ms preprocess, 177.8ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 178.9ms\n","Speed: 8.2ms preprocess, 178.9ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 170.5ms\n","Speed: 2.9ms preprocess, 170.5ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 165.4ms\n","Speed: 2.7ms preprocess, 165.4ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 176.6ms\n","Speed: 2.7ms preprocess, 176.6ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 189.1ms\n","Speed: 2.8ms preprocess, 189.1ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 180.6ms\n","Speed: 3.3ms preprocess, 180.6ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 181.1ms\n","Speed: 2.7ms preprocess, 181.1ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 169.7ms\n","Speed: 4.0ms preprocess, 169.7ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 169.9ms\n","Speed: 2.7ms preprocess, 169.9ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 174.4ms\n","Speed: 2.9ms preprocess, 174.4ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 174.1ms\n","Speed: 3.9ms preprocess, 174.1ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 184.9ms\n","Speed: 7.5ms preprocess, 184.9ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 193.8ms\n","Speed: 2.9ms preprocess, 193.8ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 171.7ms\n","Speed: 2.9ms preprocess, 171.7ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 179.4ms\n","Speed: 2.7ms preprocess, 179.4ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 183.7ms\n","Speed: 2.9ms preprocess, 183.7ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 177.7ms\n","Speed: 2.7ms preprocess, 177.7ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 174.8ms\n","Speed: 2.8ms preprocess, 174.8ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 175.4ms\n","Speed: 2.8ms preprocess, 175.4ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 125.0ms\n","Speed: 2.7ms preprocess, 125.0ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 108.9ms\n","Speed: 2.8ms preprocess, 108.9ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 127.3ms\n","Speed: 2.7ms preprocess, 127.3ms inference, 1.0ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 124.0ms\n","Speed: 2.6ms preprocess, 124.0ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 108.5ms\n","Speed: 2.9ms preprocess, 108.5ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 112.2ms\n","Speed: 3.0ms preprocess, 112.2ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 109.3ms\n","Speed: 3.5ms preprocess, 109.3ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 109.5ms\n","Speed: 2.8ms preprocess, 109.5ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 108.1ms\n","Speed: 2.7ms preprocess, 108.1ms inference, 0.9ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 108.2ms\n","Speed: 2.8ms preprocess, 108.2ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 123.9ms\n","Speed: 2.8ms preprocess, 123.9ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 126.9ms\n","Speed: 4.3ms preprocess, 126.9ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 106.3ms\n","Speed: 2.6ms preprocess, 106.3ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 117.3ms\n","Speed: 2.6ms preprocess, 117.3ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 107.6ms\n","Speed: 2.7ms preprocess, 107.6ms inference, 0.9ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 107.8ms\n","Speed: 2.4ms preprocess, 107.8ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 111.0ms\n","Speed: 2.7ms preprocess, 111.0ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 111.9ms\n","Speed: 2.6ms preprocess, 111.9ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 134.0ms\n","Speed: 3.1ms preprocess, 134.0ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 127.2ms\n","Speed: 3.1ms preprocess, 127.2ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 116.9ms\n","Speed: 2.7ms preprocess, 116.9ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 111.5ms\n","Speed: 2.9ms preprocess, 111.5ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","\n","0: 352x640 1 alpaca, 106.2ms\n","Speed: 3.8ms preprocess, 106.2ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n","Processed video: alpacaVideos3.mp4\n","\n","0: 384x640 4 alpacas, 126.9ms\n","Speed: 6.3ms preprocess, 126.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 133.7ms\n","Speed: 4.3ms preprocess, 133.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 136.1ms\n","Speed: 5.3ms preprocess, 136.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 129.4ms\n","Speed: 3.9ms preprocess, 129.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 124.4ms\n","Speed: 5.0ms preprocess, 124.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 124.6ms\n","Speed: 4.6ms preprocess, 124.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 122.2ms\n","Speed: 5.3ms preprocess, 122.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 129.8ms\n","Speed: 4.1ms preprocess, 129.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 140.0ms\n","Speed: 5.1ms preprocess, 140.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 143.6ms\n","Speed: 4.6ms preprocess, 143.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 125.3ms\n","Speed: 4.9ms preprocess, 125.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 124.7ms\n","Speed: 5.1ms preprocess, 124.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 121.3ms\n","Speed: 4.3ms preprocess, 121.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 122.4ms\n","Speed: 6.4ms preprocess, 122.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 135.0ms\n","Speed: 3.9ms preprocess, 135.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 130.2ms\n","Speed: 4.9ms preprocess, 130.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 128.1ms\n","Speed: 4.5ms preprocess, 128.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 137.5ms\n","Speed: 4.7ms preprocess, 137.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 124.2ms\n","Speed: 4.3ms preprocess, 124.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 123.4ms\n","Speed: 4.9ms preprocess, 123.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 140.1ms\n","Speed: 7.9ms preprocess, 140.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 140.6ms\n","Speed: 5.9ms preprocess, 140.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 126.8ms\n","Speed: 4.0ms preprocess, 126.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 120.4ms\n","Speed: 8.7ms preprocess, 120.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 142.7ms\n","Speed: 4.0ms preprocess, 142.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 142.3ms\n","Speed: 4.1ms preprocess, 142.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 121.1ms\n","Speed: 4.7ms preprocess, 121.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 121.8ms\n","Speed: 4.3ms preprocess, 121.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 116.1ms\n","Speed: 4.1ms preprocess, 116.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 123.6ms\n","Speed: 5.6ms preprocess, 123.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 122.8ms\n","Speed: 3.9ms preprocess, 122.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 140.8ms\n","Speed: 4.0ms preprocess, 140.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 124.1ms\n","Speed: 5.2ms preprocess, 124.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 139.7ms\n","Speed: 4.7ms preprocess, 139.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 119.9ms\n","Speed: 5.8ms preprocess, 119.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 187.5ms\n","Speed: 4.1ms preprocess, 187.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 252.8ms\n","Speed: 5.7ms preprocess, 252.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 199.4ms\n","Speed: 11.3ms preprocess, 199.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 185.7ms\n","Speed: 4.0ms preprocess, 185.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 180.7ms\n","Speed: 8.4ms preprocess, 180.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 208.9ms\n","Speed: 3.9ms preprocess, 208.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 195.1ms\n","Speed: 12.1ms preprocess, 195.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 191.7ms\n","Speed: 3.8ms preprocess, 191.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 193.3ms\n","Speed: 4.7ms preprocess, 193.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 188.2ms\n","Speed: 10.6ms preprocess, 188.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 201.7ms\n","Speed: 11.1ms preprocess, 201.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 179.9ms\n","Speed: 4.0ms preprocess, 179.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 200.8ms\n","Speed: 4.8ms preprocess, 200.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 193.5ms\n","Speed: 9.1ms preprocess, 193.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 191.1ms\n","Speed: 7.3ms preprocess, 191.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 200.5ms\n","Speed: 3.8ms preprocess, 200.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 207.6ms\n","Speed: 7.2ms preprocess, 207.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 153.1ms\n","Speed: 9.2ms preprocess, 153.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 127.4ms\n","Speed: 5.0ms preprocess, 127.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 119.8ms\n","Speed: 3.7ms preprocess, 119.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 119.3ms\n","Speed: 4.7ms preprocess, 119.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 134.0ms\n","Speed: 4.3ms preprocess, 134.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 125.7ms\n","Speed: 4.5ms preprocess, 125.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 123.5ms\n","Speed: 4.3ms preprocess, 123.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 124.8ms\n","Speed: 4.0ms preprocess, 124.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 125.8ms\n","Speed: 5.0ms preprocess, 125.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 116.2ms\n","Speed: 4.0ms preprocess, 116.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 136.5ms\n","Speed: 3.7ms preprocess, 136.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 117.8ms\n","Speed: 8.5ms preprocess, 117.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 126.4ms\n","Speed: 4.0ms preprocess, 126.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 121.6ms\n","Speed: 3.8ms preprocess, 121.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 124.4ms\n","Speed: 3.8ms preprocess, 124.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 140.6ms\n","Speed: 6.3ms preprocess, 140.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 144.5ms\n","Speed: 8.6ms preprocess, 144.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 121.1ms\n","Speed: 6.8ms preprocess, 121.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 119.1ms\n","Speed: 3.8ms preprocess, 119.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 124.3ms\n","Speed: 4.3ms preprocess, 124.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 125.4ms\n","Speed: 4.5ms preprocess, 125.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 133.4ms\n","Speed: 4.4ms preprocess, 133.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 143.6ms\n","Speed: 3.0ms preprocess, 143.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 132.5ms\n","Speed: 10.0ms preprocess, 132.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 120.8ms\n","Speed: 4.2ms preprocess, 120.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 129.4ms\n","Speed: 5.4ms preprocess, 129.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 121.9ms\n","Speed: 4.5ms preprocess, 121.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 136.0ms\n","Speed: 3.6ms preprocess, 136.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 147.2ms\n","Speed: 7.6ms preprocess, 147.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 117.9ms\n","Speed: 4.5ms preprocess, 117.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 132.1ms\n","Speed: 3.9ms preprocess, 132.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 123.8ms\n","Speed: 3.9ms preprocess, 123.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 126.2ms\n","Speed: 3.8ms preprocess, 126.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 138.4ms\n","Speed: 5.1ms preprocess, 138.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 125.5ms\n","Speed: 10.7ms preprocess, 125.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 118.6ms\n","Speed: 4.7ms preprocess, 118.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 141.2ms\n","Speed: 4.6ms preprocess, 141.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 118.0ms\n","Speed: 4.3ms preprocess, 118.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 117.6ms\n","Speed: 4.1ms preprocess, 117.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 137.7ms\n","Speed: 8.2ms preprocess, 137.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 124.2ms\n","Speed: 7.5ms preprocess, 124.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 120.8ms\n","Speed: 6.5ms preprocess, 120.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 118.7ms\n","Speed: 4.2ms preprocess, 118.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 115.5ms\n","Speed: 3.2ms preprocess, 115.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 114.0ms\n","Speed: 3.9ms preprocess, 114.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 151.2ms\n","Speed: 3.8ms preprocess, 151.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 115.8ms\n","Speed: 6.7ms preprocess, 115.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 118.1ms\n","Speed: 4.2ms preprocess, 118.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 127.1ms\n","Speed: 4.0ms preprocess, 127.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 121.1ms\n","Speed: 4.4ms preprocess, 121.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 122.2ms\n","Speed: 5.2ms preprocess, 122.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 157.9ms\n","Speed: 4.8ms preprocess, 157.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 123.8ms\n","Speed: 4.0ms preprocess, 123.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 119.6ms\n","Speed: 4.1ms preprocess, 119.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 121.7ms\n","Speed: 4.7ms preprocess, 121.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 129.4ms\n","Speed: 3.6ms preprocess, 129.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 130.9ms\n","Speed: 3.8ms preprocess, 130.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 145.8ms\n","Speed: 7.0ms preprocess, 145.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 152.7ms\n","Speed: 3.6ms preprocess, 152.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 191.7ms\n","Speed: 3.9ms preprocess, 191.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 188.8ms\n","Speed: 4.7ms preprocess, 188.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 181.0ms\n","Speed: 3.8ms preprocess, 181.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 183.2ms\n","Speed: 3.9ms preprocess, 183.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 208.2ms\n","Speed: 3.9ms preprocess, 208.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 195.8ms\n","Speed: 3.9ms preprocess, 195.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 206.0ms\n","Speed: 4.0ms preprocess, 206.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 196.9ms\n","Speed: 4.1ms preprocess, 196.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 200.2ms\n","Speed: 6.5ms preprocess, 200.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 183.7ms\n","Speed: 4.9ms preprocess, 183.7ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 196.2ms\n","Speed: 4.1ms preprocess, 196.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 201.9ms\n","Speed: 4.0ms preprocess, 201.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 204.9ms\n","Speed: 4.3ms preprocess, 204.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 193.2ms\n","Speed: 4.0ms preprocess, 193.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 217.4ms\n","Speed: 5.2ms preprocess, 217.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 196.9ms\n","Speed: 4.9ms preprocess, 196.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 211.2ms\n","Speed: 3.8ms preprocess, 211.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 190.3ms\n","Speed: 4.6ms preprocess, 190.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 148.3ms\n","Speed: 3.9ms preprocess, 148.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 121.4ms\n","Speed: 3.9ms preprocess, 121.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 139.4ms\n","Speed: 3.8ms preprocess, 139.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 121.6ms\n","Speed: 4.1ms preprocess, 121.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 133.4ms\n","Speed: 3.9ms preprocess, 133.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 125.8ms\n","Speed: 3.9ms preprocess, 125.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 140.4ms\n","Speed: 5.5ms preprocess, 140.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 122.3ms\n","Speed: 3.5ms preprocess, 122.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 136.0ms\n","Speed: 4.8ms preprocess, 136.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 121.6ms\n","Speed: 6.4ms preprocess, 121.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 125.5ms\n","Speed: 4.5ms preprocess, 125.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 126.4ms\n","Speed: 3.8ms preprocess, 126.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 152.5ms\n","Speed: 4.1ms preprocess, 152.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 121.6ms\n","Speed: 4.1ms preprocess, 121.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 130.3ms\n","Speed: 8.1ms preprocess, 130.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 124.2ms\n","Speed: 4.6ms preprocess, 124.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 124.2ms\n","Speed: 3.7ms preprocess, 124.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 125.7ms\n","Speed: 3.8ms preprocess, 125.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 147.2ms\n","Speed: 3.9ms preprocess, 147.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 119.6ms\n","Speed: 3.8ms preprocess, 119.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 147.5ms\n","Speed: 3.8ms preprocess, 147.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 119.4ms\n","Speed: 4.5ms preprocess, 119.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 122.2ms\n","Speed: 4.6ms preprocess, 122.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 127.5ms\n","Speed: 5.2ms preprocess, 127.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 133.4ms\n","Speed: 4.1ms preprocess, 133.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 125.1ms\n","Speed: 4.2ms preprocess, 125.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 132.6ms\n","Speed: 4.3ms preprocess, 132.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 127.4ms\n","Speed: 4.9ms preprocess, 127.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 123.2ms\n","Speed: 3.8ms preprocess, 123.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 134.4ms\n","Speed: 5.0ms preprocess, 134.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 121.9ms\n","Speed: 3.4ms preprocess, 121.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 119.8ms\n","Speed: 3.7ms preprocess, 119.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 141.6ms\n","Speed: 3.7ms preprocess, 141.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 128.3ms\n","Speed: 7.4ms preprocess, 128.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 119.6ms\n","Speed: 4.1ms preprocess, 119.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 145.4ms\n","Speed: 4.2ms preprocess, 145.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 131.0ms\n","Speed: 3.7ms preprocess, 131.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 123.8ms\n","Speed: 3.9ms preprocess, 123.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 134.8ms\n","Speed: 4.1ms preprocess, 134.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 126.2ms\n","Speed: 5.6ms preprocess, 126.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 126.0ms\n","Speed: 4.5ms preprocess, 126.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 142.0ms\n","Speed: 7.9ms preprocess, 142.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 123.1ms\n","Speed: 5.1ms preprocess, 123.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 128.0ms\n","Speed: 4.2ms preprocess, 128.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 139.9ms\n","Speed: 4.2ms preprocess, 139.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 121.4ms\n","Speed: 4.2ms preprocess, 121.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 122.9ms\n","Speed: 3.9ms preprocess, 122.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 151.7ms\n","Speed: 4.4ms preprocess, 151.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 123.5ms\n","Speed: 4.1ms preprocess, 123.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 120.5ms\n","Speed: 4.0ms preprocess, 120.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 162.5ms\n","Speed: 3.8ms preprocess, 162.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 126.1ms\n","Speed: 3.9ms preprocess, 126.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 127.5ms\n","Speed: 5.6ms preprocess, 127.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 134.9ms\n","Speed: 9.9ms preprocess, 134.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 117.7ms\n","Speed: 4.0ms preprocess, 117.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 133.6ms\n","Speed: 5.0ms preprocess, 133.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 134.7ms\n","Speed: 5.0ms preprocess, 134.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 115.9ms\n","Speed: 3.9ms preprocess, 115.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 184.2ms\n","Speed: 4.1ms preprocess, 184.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 183.9ms\n","Speed: 6.5ms preprocess, 183.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 196.0ms\n","Speed: 4.3ms preprocess, 196.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 199.7ms\n","Speed: 4.7ms preprocess, 199.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 202.4ms\n","Speed: 4.1ms preprocess, 202.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 187.3ms\n","Speed: 4.5ms preprocess, 187.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 198.4ms\n","Speed: 13.7ms preprocess, 198.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 199.4ms\n","Speed: 6.2ms preprocess, 199.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 194.1ms\n","Speed: 6.2ms preprocess, 194.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 184.6ms\n","Speed: 9.8ms preprocess, 184.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 186.2ms\n","Speed: 9.8ms preprocess, 186.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 206.2ms\n","Speed: 3.9ms preprocess, 206.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 214.7ms\n","Speed: 6.4ms preprocess, 214.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 206.2ms\n","Speed: 7.3ms preprocess, 206.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 201.5ms\n","Speed: 5.0ms preprocess, 201.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 218.9ms\n","Speed: 5.1ms preprocess, 218.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 191.6ms\n","Speed: 4.0ms preprocess, 191.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 157.2ms\n","Speed: 4.1ms preprocess, 157.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 124.8ms\n","Speed: 3.8ms preprocess, 124.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 118.1ms\n","Speed: 4.0ms preprocess, 118.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 144.0ms\n","Speed: 3.8ms preprocess, 144.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 127.6ms\n","Speed: 6.0ms preprocess, 127.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 130.8ms\n","Speed: 4.9ms preprocess, 130.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 118.2ms\n","Speed: 3.9ms preprocess, 118.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 119.9ms\n","Speed: 4.3ms preprocess, 119.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 118.8ms\n","Speed: 4.3ms preprocess, 118.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 149.3ms\n","Speed: 4.3ms preprocess, 149.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 128.7ms\n","Speed: 3.9ms preprocess, 128.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 127.5ms\n","Speed: 5.2ms preprocess, 127.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 117.3ms\n","Speed: 3.4ms preprocess, 117.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 133.5ms\n","Speed: 3.7ms preprocess, 133.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 120.0ms\n","Speed: 3.9ms preprocess, 120.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 147.6ms\n","Speed: 4.1ms preprocess, 147.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 120.7ms\n","Speed: 4.1ms preprocess, 120.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 124.7ms\n","Speed: 4.0ms preprocess, 124.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 121.8ms\n","Speed: 5.2ms preprocess, 121.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 123.5ms\n","Speed: 4.3ms preprocess, 123.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 117.2ms\n","Speed: 4.5ms preprocess, 117.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 163.7ms\n","Speed: 4.6ms preprocess, 163.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 122.5ms\n","Speed: 4.1ms preprocess, 122.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 127.0ms\n","Speed: 4.1ms preprocess, 127.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 120.2ms\n","Speed: 4.2ms preprocess, 120.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 123.5ms\n","Speed: 4.0ms preprocess, 123.5ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 131.0ms\n","Speed: 4.1ms preprocess, 131.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 153.1ms\n","Speed: 3.8ms preprocess, 153.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 128.9ms\n","Speed: 4.0ms preprocess, 128.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 120.7ms\n","Speed: 5.0ms preprocess, 120.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 120.0ms\n","Speed: 4.8ms preprocess, 120.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 127.0ms\n","Speed: 6.0ms preprocess, 127.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 123.3ms\n","Speed: 4.1ms preprocess, 123.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 159.1ms\n","Speed: 5.4ms preprocess, 159.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 122.9ms\n","Speed: 5.4ms preprocess, 122.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 117.3ms\n","Speed: 4.3ms preprocess, 117.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 119.1ms\n","Speed: 4.1ms preprocess, 119.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 128.3ms\n","Speed: 4.0ms preprocess, 128.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 123.5ms\n","Speed: 4.9ms preprocess, 123.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 148.6ms\n","Speed: 4.8ms preprocess, 148.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 119.3ms\n","Speed: 5.0ms preprocess, 119.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 119.7ms\n","Speed: 4.1ms preprocess, 119.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 122.8ms\n","Speed: 4.1ms preprocess, 122.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 126.2ms\n","Speed: 3.7ms preprocess, 126.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 119.1ms\n","Speed: 4.2ms preprocess, 119.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 151.2ms\n","Speed: 4.4ms preprocess, 151.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 119.2ms\n","Speed: 3.7ms preprocess, 119.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 119.1ms\n","Speed: 4.0ms preprocess, 119.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 116.5ms\n","Speed: 4.2ms preprocess, 116.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 125.3ms\n","Speed: 5.9ms preprocess, 125.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 119.5ms\n","Speed: 5.5ms preprocess, 119.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","Processed video: alpacaVideos4.mp4\n","\n","0: 384x640 2 alpacas, 131.1ms\n","Speed: 4.6ms preprocess, 131.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 132.3ms\n","Speed: 3.9ms preprocess, 132.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 187.1ms\n","Speed: 9.5ms preprocess, 187.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 193.6ms\n","Speed: 4.0ms preprocess, 193.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 195.6ms\n","Speed: 6.5ms preprocess, 195.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 194.7ms\n","Speed: 4.3ms preprocess, 194.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 181.4ms\n","Speed: 7.2ms preprocess, 181.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 188.7ms\n","Speed: 9.7ms preprocess, 188.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 204.8ms\n","Speed: 4.1ms preprocess, 204.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 205.6ms\n","Speed: 8.0ms preprocess, 205.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 194.1ms\n","Speed: 4.1ms preprocess, 194.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 187.9ms\n","Speed: 5.3ms preprocess, 187.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 185.8ms\n","Speed: 4.1ms preprocess, 185.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 196.5ms\n","Speed: 10.5ms preprocess, 196.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 187.5ms\n","Speed: 10.5ms preprocess, 187.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 207.8ms\n","Speed: 3.9ms preprocess, 207.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 201.7ms\n","Speed: 4.1ms preprocess, 201.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 217.9ms\n","Speed: 4.3ms preprocess, 217.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 219.4ms\n","Speed: 8.1ms preprocess, 219.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 171.1ms\n","Speed: 4.1ms preprocess, 171.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 116.4ms\n","Speed: 9.9ms preprocess, 116.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 122.3ms\n","Speed: 5.7ms preprocess, 122.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 150.3ms\n","Speed: 4.4ms preprocess, 150.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 127.9ms\n","Speed: 5.2ms preprocess, 127.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 125.0ms\n","Speed: 3.8ms preprocess, 125.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 141.6ms\n","Speed: 3.9ms preprocess, 141.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 121.5ms\n","Speed: 4.1ms preprocess, 121.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 122.6ms\n","Speed: 5.1ms preprocess, 122.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 138.5ms\n","Speed: 4.1ms preprocess, 138.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 122.5ms\n","Speed: 4.0ms preprocess, 122.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 128.5ms\n","Speed: 4.0ms preprocess, 128.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 158.8ms\n","Speed: 13.8ms preprocess, 158.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 119.7ms\n","Speed: 4.8ms preprocess, 119.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 138.6ms\n","Speed: 3.9ms preprocess, 138.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 149.2ms\n","Speed: 4.2ms preprocess, 149.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 128.6ms\n","Speed: 7.3ms preprocess, 128.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 132.0ms\n","Speed: 10.4ms preprocess, 132.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 119.9ms\n","Speed: 4.2ms preprocess, 119.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 128.3ms\n","Speed: 7.8ms preprocess, 128.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 136.1ms\n","Speed: 4.2ms preprocess, 136.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 120.6ms\n","Speed: 5.3ms preprocess, 120.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 128.0ms\n","Speed: 6.2ms preprocess, 128.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 133.0ms\n","Speed: 7.7ms preprocess, 133.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 114.3ms\n","Speed: 4.1ms preprocess, 114.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 120.0ms\n","Speed: 6.9ms preprocess, 120.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 135.0ms\n","Speed: 4.6ms preprocess, 135.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 121.5ms\n","Speed: 3.8ms preprocess, 121.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 133.3ms\n","Speed: 3.9ms preprocess, 133.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 130.8ms\n","Speed: 7.0ms preprocess, 130.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 118.1ms\n","Speed: 4.3ms preprocess, 118.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 131.9ms\n","Speed: 4.3ms preprocess, 131.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 136.5ms\n","Speed: 4.4ms preprocess, 136.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 124.3ms\n","Speed: 4.2ms preprocess, 124.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 144.4ms\n","Speed: 5.4ms preprocess, 144.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 126.9ms\n","Speed: 4.0ms preprocess, 126.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 120.3ms\n","Speed: 4.7ms preprocess, 120.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 119.6ms\n","Speed: 4.6ms preprocess, 119.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 133.8ms\n","Speed: 5.4ms preprocess, 133.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 128.9ms\n","Speed: 4.1ms preprocess, 128.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 144.2ms\n","Speed: 4.1ms preprocess, 144.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 130.9ms\n","Speed: 4.3ms preprocess, 130.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 123.4ms\n","Speed: 4.3ms preprocess, 123.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 117.4ms\n","Speed: 4.1ms preprocess, 117.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 127.9ms\n","Speed: 4.3ms preprocess, 127.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 126.7ms\n","Speed: 5.9ms preprocess, 126.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 151.0ms\n","Speed: 8.2ms preprocess, 151.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 124.0ms\n","Speed: 4.7ms preprocess, 124.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 120.4ms\n","Speed: 4.4ms preprocess, 120.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 124.4ms\n","Speed: 5.0ms preprocess, 124.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 123.3ms\n","Speed: 4.2ms preprocess, 123.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 129.5ms\n","Speed: 4.7ms preprocess, 129.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 138.7ms\n","Speed: 3.9ms preprocess, 138.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 120.5ms\n","Speed: 4.6ms preprocess, 120.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 135.2ms\n","Speed: 4.6ms preprocess, 135.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 121.9ms\n","Speed: 5.1ms preprocess, 121.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 117.7ms\n","Speed: 4.2ms preprocess, 117.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 139.7ms\n","Speed: 4.0ms preprocess, 139.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 197.1ms\n","Speed: 4.0ms preprocess, 197.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 190.1ms\n","Speed: 4.6ms preprocess, 190.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 197.9ms\n","Speed: 4.1ms preprocess, 197.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 208.5ms\n","Speed: 9.2ms preprocess, 208.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 181.4ms\n","Speed: 8.4ms preprocess, 181.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 186.3ms\n","Speed: 9.0ms preprocess, 186.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 193.7ms\n","Speed: 4.0ms preprocess, 193.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 201.6ms\n","Speed: 4.7ms preprocess, 201.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 195.2ms\n","Speed: 7.0ms preprocess, 195.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 181.4ms\n","Speed: 4.0ms preprocess, 181.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 191.6ms\n","Speed: 4.9ms preprocess, 191.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 184.5ms\n","Speed: 4.8ms preprocess, 184.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 198.1ms\n","Speed: 7.5ms preprocess, 198.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 198.8ms\n","Speed: 4.9ms preprocess, 198.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 203.8ms\n","Speed: 8.0ms preprocess, 203.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 199.6ms\n","Speed: 7.0ms preprocess, 199.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 217.7ms\n","Speed: 4.0ms preprocess, 217.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 186.8ms\n","Speed: 4.2ms preprocess, 186.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 159.9ms\n","Speed: 3.9ms preprocess, 159.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 119.6ms\n","Speed: 3.9ms preprocess, 119.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 138.2ms\n","Speed: 3.9ms preprocess, 138.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 133.8ms\n","Speed: 5.4ms preprocess, 133.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 116.7ms\n","Speed: 6.6ms preprocess, 116.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 118.5ms\n","Speed: 3.9ms preprocess, 118.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 127.0ms\n","Speed: 4.0ms preprocess, 127.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 120.0ms\n","Speed: 4.3ms preprocess, 120.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 142.1ms\n","Speed: 6.6ms preprocess, 142.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 129.8ms\n","Speed: 8.2ms preprocess, 129.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 117.3ms\n","Speed: 4.1ms preprocess, 117.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 120.6ms\n","Speed: 4.2ms preprocess, 120.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 127.2ms\n","Speed: 3.8ms preprocess, 127.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 122.1ms\n","Speed: 4.3ms preprocess, 122.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 143.0ms\n","Speed: 4.6ms preprocess, 143.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 120.1ms\n","Speed: 5.7ms preprocess, 120.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 121.2ms\n","Speed: 5.0ms preprocess, 121.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 120.0ms\n","Speed: 4.1ms preprocess, 120.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 130.3ms\n","Speed: 4.0ms preprocess, 130.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 127.7ms\n","Speed: 4.1ms preprocess, 127.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 157.2ms\n","Speed: 4.0ms preprocess, 157.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 124.6ms\n","Speed: 4.8ms preprocess, 124.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 121.8ms\n","Speed: 4.2ms preprocess, 121.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 121.0ms\n","Speed: 3.8ms preprocess, 121.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 129.1ms\n","Speed: 3.9ms preprocess, 129.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 123.0ms\n","Speed: 4.1ms preprocess, 123.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 141.6ms\n","Speed: 4.2ms preprocess, 141.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 120.6ms\n","Speed: 3.9ms preprocess, 120.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 130.1ms\n","Speed: 5.9ms preprocess, 130.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 122.7ms\n","Speed: 4.2ms preprocess, 122.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 126.4ms\n","Speed: 4.2ms preprocess, 126.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 121.4ms\n","Speed: 9.2ms preprocess, 121.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 132.3ms\n","Speed: 6.5ms preprocess, 132.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 122.3ms\n","Speed: 4.4ms preprocess, 122.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 137.5ms\n","Speed: 4.0ms preprocess, 137.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 118.3ms\n","Speed: 4.2ms preprocess, 118.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 121.5ms\n","Speed: 4.1ms preprocess, 121.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 122.7ms\n","Speed: 4.1ms preprocess, 122.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 132.7ms\n","Speed: 8.4ms preprocess, 132.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 121.3ms\n","Speed: 4.5ms preprocess, 121.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 147.1ms\n","Speed: 4.0ms preprocess, 147.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 117.7ms\n","Speed: 4.1ms preprocess, 117.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 121.4ms\n","Speed: 4.2ms preprocess, 121.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 135.1ms\n","Speed: 4.9ms preprocess, 135.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 125.4ms\n","Speed: 4.6ms preprocess, 125.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 117.6ms\n","Speed: 4.1ms preprocess, 117.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 131.1ms\n","Speed: 4.4ms preprocess, 131.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 127.6ms\n","Speed: 3.9ms preprocess, 127.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 125.8ms\n","Speed: 4.2ms preprocess, 125.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 136.6ms\n","Speed: 3.7ms preprocess, 136.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 121.6ms\n","Speed: 8.3ms preprocess, 121.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 120.0ms\n","Speed: 5.1ms preprocess, 120.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 133.0ms\n","Speed: 3.9ms preprocess, 133.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 121.6ms\n","Speed: 4.0ms preprocess, 121.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 128.2ms\n","Speed: 4.1ms preprocess, 128.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 141.8ms\n","Speed: 4.5ms preprocess, 141.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 124.7ms\n","Speed: 4.1ms preprocess, 124.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 119.6ms\n","Speed: 4.1ms preprocess, 119.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 131.1ms\n","Speed: 3.8ms preprocess, 131.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 149.3ms\n","Speed: 3.9ms preprocess, 149.3ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 203.7ms\n","Speed: 4.1ms preprocess, 203.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 196.3ms\n","Speed: 3.9ms preprocess, 196.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 194.5ms\n","Speed: 8.9ms preprocess, 194.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 200.1ms\n","Speed: 7.8ms preprocess, 200.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 177.9ms\n","Speed: 3.8ms preprocess, 177.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 197.0ms\n","Speed: 4.0ms preprocess, 197.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 185.1ms\n","Speed: 6.9ms preprocess, 185.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 194.5ms\n","Speed: 4.3ms preprocess, 194.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 230.9ms\n","Speed: 4.1ms preprocess, 230.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 191.7ms\n","Speed: 6.0ms preprocess, 191.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 179.2ms\n","Speed: 4.2ms preprocess, 179.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 201.6ms\n","Speed: 4.1ms preprocess, 201.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 204.5ms\n","Speed: 4.1ms preprocess, 204.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 197.3ms\n","Speed: 10.5ms preprocess, 197.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 187.9ms\n","Speed: 9.4ms preprocess, 187.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 200.5ms\n","Speed: 4.1ms preprocess, 200.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 200.2ms\n","Speed: 4.0ms preprocess, 200.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 174.8ms\n","Speed: 4.0ms preprocess, 174.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","Processed video: alpacaVideos2.mp4\n","\n","0: 384x640 4 alpacas, 123.1ms\n","Speed: 4.1ms preprocess, 123.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 128.3ms\n","Speed: 4.0ms preprocess, 128.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 5 alpacas, 155.5ms\n","Speed: 7.6ms preprocess, 155.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 5 alpacas, 132.2ms\n","Speed: 4.0ms preprocess, 132.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 125.6ms\n","Speed: 4.0ms preprocess, 125.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 128.9ms\n","Speed: 3.9ms preprocess, 128.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 120.1ms\n","Speed: 6.7ms preprocess, 120.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 148.3ms\n","Speed: 4.3ms preprocess, 148.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 142.2ms\n","Speed: 4.1ms preprocess, 142.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 132.5ms\n","Speed: 3.8ms preprocess, 132.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 123.7ms\n","Speed: 13.0ms preprocess, 123.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 121.5ms\n","Speed: 3.7ms preprocess, 121.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 134.2ms\n","Speed: 4.4ms preprocess, 134.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 133.4ms\n","Speed: 4.9ms preprocess, 133.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 151.8ms\n","Speed: 4.0ms preprocess, 151.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 126.1ms\n","Speed: 4.2ms preprocess, 126.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 126.8ms\n","Speed: 4.0ms preprocess, 126.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 128.2ms\n","Speed: 3.7ms preprocess, 128.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 128.4ms\n","Speed: 3.9ms preprocess, 128.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 141.4ms\n","Speed: 4.4ms preprocess, 141.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 145.1ms\n","Speed: 4.2ms preprocess, 145.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 121.3ms\n","Speed: 10.0ms preprocess, 121.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 127.3ms\n","Speed: 4.0ms preprocess, 127.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 120.9ms\n","Speed: 10.5ms preprocess, 120.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 130.9ms\n","Speed: 4.5ms preprocess, 130.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 150.8ms\n","Speed: 3.9ms preprocess, 150.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 128.3ms\n","Speed: 4.1ms preprocess, 128.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 122.0ms\n","Speed: 3.8ms preprocess, 122.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 120.6ms\n","Speed: 3.8ms preprocess, 120.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 128.5ms\n","Speed: 4.2ms preprocess, 128.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 123.9ms\n","Speed: 4.4ms preprocess, 123.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 160.1ms\n","Speed: 3.7ms preprocess, 160.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 129.2ms\n","Speed: 3.8ms preprocess, 129.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 127.9ms\n","Speed: 3.8ms preprocess, 127.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 123.3ms\n","Speed: 3.9ms preprocess, 123.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 124.6ms\n","Speed: 4.0ms preprocess, 124.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 128.8ms\n","Speed: 4.3ms preprocess, 128.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 156.3ms\n","Speed: 7.3ms preprocess, 156.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 127.3ms\n","Speed: 8.2ms preprocess, 127.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 125.7ms\n","Speed: 4.1ms preprocess, 125.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 119.1ms\n","Speed: 4.0ms preprocess, 119.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 129.3ms\n","Speed: 4.0ms preprocess, 129.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 135.8ms\n","Speed: 4.4ms preprocess, 135.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 153.3ms\n","Speed: 19.5ms preprocess, 153.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 125.0ms\n","Speed: 4.2ms preprocess, 125.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 130.2ms\n","Speed: 4.4ms preprocess, 130.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 117.2ms\n","Speed: 3.8ms preprocess, 117.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 128.9ms\n","Speed: 5.1ms preprocess, 128.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 149.2ms\n","Speed: 4.1ms preprocess, 149.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 130.9ms\n","Speed: 4.0ms preprocess, 130.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 121.5ms\n","Speed: 4.1ms preprocess, 121.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 133.8ms\n","Speed: 4.3ms preprocess, 133.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 118.7ms\n","Speed: 4.1ms preprocess, 118.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 122.1ms\n","Speed: 7.6ms preprocess, 122.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 148.6ms\n","Speed: 7.9ms preprocess, 148.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 160.0ms\n","Speed: 4.4ms preprocess, 160.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 191.9ms\n","Speed: 3.8ms preprocess, 191.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 205.6ms\n","Speed: 4.0ms preprocess, 205.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 192.8ms\n","Speed: 4.0ms preprocess, 192.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 212.1ms\n","Speed: 4.3ms preprocess, 212.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 177.3ms\n","Speed: 3.8ms preprocess, 177.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 198.2ms\n","Speed: 8.5ms preprocess, 198.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 207.2ms\n","Speed: 4.0ms preprocess, 207.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 207.4ms\n","Speed: 4.1ms preprocess, 207.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 201.8ms\n","Speed: 3.9ms preprocess, 201.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 192.1ms\n","Speed: 4.3ms preprocess, 192.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 193.0ms\n","Speed: 3.9ms preprocess, 193.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 191.3ms\n","Speed: 4.1ms preprocess, 191.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 196.0ms\n","Speed: 3.9ms preprocess, 196.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 195.7ms\n","Speed: 10.7ms preprocess, 195.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 201.7ms\n","Speed: 4.0ms preprocess, 201.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 200.1ms\n","Speed: 4.3ms preprocess, 200.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 205.4ms\n","Speed: 4.2ms preprocess, 205.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 198.3ms\n","Speed: 10.6ms preprocess, 198.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 160.9ms\n","Speed: 6.4ms preprocess, 160.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 123.0ms\n","Speed: 4.0ms preprocess, 123.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 131.7ms\n","Speed: 4.3ms preprocess, 131.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 131.7ms\n","Speed: 3.3ms preprocess, 131.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 124.5ms\n","Speed: 4.8ms preprocess, 124.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 137.3ms\n","Speed: 3.9ms preprocess, 137.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 128.9ms\n","Speed: 4.2ms preprocess, 128.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 121.1ms\n","Speed: 3.9ms preprocess, 121.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 144.0ms\n","Speed: 4.1ms preprocess, 144.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 123.8ms\n","Speed: 4.2ms preprocess, 123.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 124.0ms\n","Speed: 4.0ms preprocess, 124.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 141.7ms\n","Speed: 4.1ms preprocess, 141.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 126.7ms\n","Speed: 6.4ms preprocess, 126.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 121.9ms\n","Speed: 4.0ms preprocess, 121.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 135.5ms\n","Speed: 4.0ms preprocess, 135.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 122.5ms\n","Speed: 4.0ms preprocess, 122.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 126.2ms\n","Speed: 4.0ms preprocess, 126.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 140.6ms\n","Speed: 4.4ms preprocess, 140.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 125.4ms\n","Speed: 3.9ms preprocess, 125.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 124.0ms\n","Speed: 5.2ms preprocess, 124.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 129.9ms\n","Speed: 5.3ms preprocess, 129.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 122.3ms\n","Speed: 4.2ms preprocess, 122.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 123.3ms\n","Speed: 4.1ms preprocess, 123.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 140.1ms\n","Speed: 5.3ms preprocess, 140.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 128.4ms\n","Speed: 4.3ms preprocess, 128.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 130.0ms\n","Speed: 3.2ms preprocess, 130.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 134.2ms\n","Speed: 4.1ms preprocess, 134.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 117.0ms\n","Speed: 10.9ms preprocess, 117.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 130.5ms\n","Speed: 4.1ms preprocess, 130.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 129.0ms\n","Speed: 4.1ms preprocess, 129.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 137.8ms\n","Speed: 4.9ms preprocess, 137.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 127.9ms\n","Speed: 4.0ms preprocess, 127.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 137.9ms\n","Speed: 4.7ms preprocess, 137.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 115.6ms\n","Speed: 11.5ms preprocess, 115.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 144.8ms\n","Speed: 4.0ms preprocess, 144.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 118.9ms\n","Speed: 4.2ms preprocess, 118.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 124.4ms\n","Speed: 4.1ms preprocess, 124.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 122.0ms\n","Speed: 5.3ms preprocess, 122.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 134.8ms\n","Speed: 4.0ms preprocess, 134.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 118.3ms\n","Speed: 3.8ms preprocess, 118.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 154.3ms\n","Speed: 3.8ms preprocess, 154.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 121.7ms\n","Speed: 3.8ms preprocess, 121.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 127.4ms\n","Speed: 3.6ms preprocess, 127.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 131.5ms\n","Speed: 4.4ms preprocess, 131.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 127.0ms\n","Speed: 4.0ms preprocess, 127.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 129.0ms\n","Speed: 4.1ms preprocess, 129.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 142.3ms\n","Speed: 4.8ms preprocess, 142.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 138.8ms\n","Speed: 5.5ms preprocess, 138.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 122.6ms\n","Speed: 4.4ms preprocess, 122.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 126.6ms\n","Speed: 4.6ms preprocess, 126.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 126.6ms\n","Speed: 11.1ms preprocess, 126.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 123.7ms\n","Speed: 4.7ms preprocess, 123.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 136.5ms\n","Speed: 4.4ms preprocess, 136.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 122.2ms\n","Speed: 4.1ms preprocess, 122.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 124.7ms\n","Speed: 5.0ms preprocess, 124.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 140.2ms\n","Speed: 3.9ms preprocess, 140.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 121.7ms\n","Speed: 4.0ms preprocess, 121.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 155.8ms\n","Speed: 4.0ms preprocess, 155.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 195.3ms\n","Speed: 3.9ms preprocess, 195.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 196.6ms\n","Speed: 6.1ms preprocess, 196.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 223.3ms\n","Speed: 11.8ms preprocess, 223.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 209.0ms\n","Speed: 6.0ms preprocess, 209.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 186.5ms\n","Speed: 8.4ms preprocess, 186.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 207.0ms\n","Speed: 7.9ms preprocess, 207.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 215.1ms\n","Speed: 4.1ms preprocess, 215.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 191.7ms\n","Speed: 10.1ms preprocess, 191.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 191.5ms\n","Speed: 10.2ms preprocess, 191.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 208.5ms\n","Speed: 7.2ms preprocess, 208.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 217.5ms\n","Speed: 4.0ms preprocess, 217.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 200.6ms\n","Speed: 7.3ms preprocess, 200.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 209.6ms\n","Speed: 5.4ms preprocess, 209.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 195.8ms\n","Speed: 5.9ms preprocess, 195.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 222.7ms\n","Speed: 4.1ms preprocess, 222.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 200.6ms\n","Speed: 8.0ms preprocess, 200.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 181.6ms\n","Speed: 4.8ms preprocess, 181.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 127.1ms\n","Speed: 4.9ms preprocess, 127.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 130.3ms\n","Speed: 4.0ms preprocess, 130.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 150.5ms\n","Speed: 4.9ms preprocess, 150.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 129.1ms\n","Speed: 4.4ms preprocess, 129.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 131.0ms\n","Speed: 4.2ms preprocess, 131.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 129.9ms\n","Speed: 3.9ms preprocess, 129.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 132.7ms\n","Speed: 4.2ms preprocess, 132.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 128.4ms\n","Speed: 3.9ms preprocess, 128.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 165.1ms\n","Speed: 10.3ms preprocess, 165.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 121.2ms\n","Speed: 4.3ms preprocess, 121.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 125.9ms\n","Speed: 4.3ms preprocess, 125.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 125.0ms\n","Speed: 4.0ms preprocess, 125.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 120.7ms\n","Speed: 3.8ms preprocess, 120.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 155.3ms\n","Speed: 3.9ms preprocess, 155.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 137.3ms\n","Speed: 4.0ms preprocess, 137.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 130.5ms\n","Speed: 4.5ms preprocess, 130.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 126.3ms\n","Speed: 5.2ms preprocess, 126.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 117.3ms\n","Speed: 3.8ms preprocess, 117.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 127.7ms\n","Speed: 3.9ms preprocess, 127.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 141.6ms\n","Speed: 3.8ms preprocess, 141.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 137.2ms\n","Speed: 5.9ms preprocess, 137.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 121.6ms\n","Speed: 3.8ms preprocess, 121.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 125.2ms\n","Speed: 3.7ms preprocess, 125.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 126.8ms\n","Speed: 4.3ms preprocess, 126.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 126.9ms\n","Speed: 4.0ms preprocess, 126.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 129.1ms\n","Speed: 4.2ms preprocess, 129.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 131.9ms\n","Speed: 4.1ms preprocess, 131.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 124.6ms\n","Speed: 4.0ms preprocess, 124.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 131.1ms\n","Speed: 5.5ms preprocess, 131.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 123.6ms\n","Speed: 3.9ms preprocess, 123.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 139.0ms\n","Speed: 5.0ms preprocess, 139.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 124.2ms\n","Speed: 6.4ms preprocess, 124.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 145.0ms\n","Speed: 4.3ms preprocess, 145.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 136.2ms\n","Speed: 4.7ms preprocess, 136.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 123.2ms\n","Speed: 3.8ms preprocess, 123.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 124.8ms\n","Speed: 3.9ms preprocess, 124.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 159.9ms\n","Speed: 3.9ms preprocess, 159.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 124.1ms\n","Speed: 3.9ms preprocess, 124.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 140.8ms\n","Speed: 4.4ms preprocess, 140.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 122.7ms\n","Speed: 3.9ms preprocess, 122.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 129.8ms\n","Speed: 4.4ms preprocess, 129.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 118.4ms\n","Speed: 3.8ms preprocess, 118.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 139.2ms\n","Speed: 4.1ms preprocess, 139.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 123.9ms\n","Speed: 3.7ms preprocess, 123.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 130.2ms\n","Speed: 5.6ms preprocess, 130.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 134.3ms\n","Speed: 3.7ms preprocess, 134.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 120.8ms\n","Speed: 3.9ms preprocess, 120.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 129.9ms\n","Speed: 4.4ms preprocess, 129.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 129.7ms\n","Speed: 8.5ms preprocess, 129.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 123.6ms\n","Speed: 3.8ms preprocess, 123.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 142.6ms\n","Speed: 4.3ms preprocess, 142.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 122.0ms\n","Speed: 3.9ms preprocess, 122.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 129.5ms\n","Speed: 5.4ms preprocess, 129.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 140.5ms\n","Speed: 5.3ms preprocess, 140.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 124.7ms\n","Speed: 4.2ms preprocess, 124.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 129.5ms\n","Speed: 4.0ms preprocess, 129.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 135.5ms\n","Speed: 4.3ms preprocess, 135.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 193.9ms\n","Speed: 4.0ms preprocess, 193.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 208.6ms\n","Speed: 9.3ms preprocess, 208.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 182.7ms\n","Speed: 13.4ms preprocess, 182.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 210.0ms\n","Speed: 8.0ms preprocess, 210.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 184.4ms\n","Speed: 4.2ms preprocess, 184.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 206.8ms\n","Speed: 14.5ms preprocess, 206.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 196.2ms\n","Speed: 4.3ms preprocess, 196.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 219.3ms\n","Speed: 6.6ms preprocess, 219.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 193.2ms\n","Speed: 10.6ms preprocess, 193.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 200.8ms\n","Speed: 13.1ms preprocess, 200.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 185.5ms\n","Speed: 7.9ms preprocess, 185.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 204.6ms\n","Speed: 4.2ms preprocess, 204.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 207.1ms\n","Speed: 4.0ms preprocess, 207.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 192.8ms\n","Speed: 9.2ms preprocess, 192.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 204.2ms\n","Speed: 4.0ms preprocess, 204.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 213.4ms\n","Speed: 7.0ms preprocess, 213.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 211.1ms\n","Speed: 4.3ms preprocess, 211.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 154.3ms\n","Speed: 4.0ms preprocess, 154.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 131.1ms\n","Speed: 4.8ms preprocess, 131.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 136.2ms\n","Speed: 5.0ms preprocess, 136.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 131.4ms\n","Speed: 3.9ms preprocess, 131.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 125.0ms\n","Speed: 4.4ms preprocess, 125.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 145.7ms\n","Speed: 4.3ms preprocess, 145.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 125.8ms\n","Speed: 4.3ms preprocess, 125.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 122.4ms\n","Speed: 4.2ms preprocess, 122.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 141.3ms\n","Speed: 3.9ms preprocess, 141.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 134.9ms\n","Speed: 4.1ms preprocess, 134.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 144.6ms\n","Speed: 7.1ms preprocess, 144.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 136.7ms\n","Speed: 4.3ms preprocess, 136.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 130.1ms\n","Speed: 4.0ms preprocess, 130.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 127.7ms\n","Speed: 4.0ms preprocess, 127.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 129.1ms\n","Speed: 3.9ms preprocess, 129.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 147.4ms\n","Speed: 3.9ms preprocess, 147.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 138.7ms\n","Speed: 7.2ms preprocess, 138.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 125.7ms\n","Speed: 3.7ms preprocess, 125.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 130.9ms\n","Speed: 4.5ms preprocess, 130.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 127.4ms\n","Speed: 4.2ms preprocess, 127.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 125.9ms\n","Speed: 4.0ms preprocess, 125.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 141.6ms\n","Speed: 9.3ms preprocess, 141.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 127.4ms\n","Speed: 5.7ms preprocess, 127.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 126.8ms\n","Speed: 3.8ms preprocess, 126.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 117.4ms\n","Speed: 4.9ms preprocess, 117.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 118.3ms\n","Speed: 5.8ms preprocess, 118.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","Processed video: alpacaVideos1.mp4\n","\n","0: 384x640 7 alpacas, 122.6ms\n","Speed: 5.8ms preprocess, 122.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 alpacas, 136.2ms\n","Speed: 8.4ms preprocess, 136.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 alpacas, 120.0ms\n","Speed: 3.9ms preprocess, 120.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 alpacas, 118.5ms\n","Speed: 9.1ms preprocess, 118.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 5 alpacas, 115.4ms\n","Speed: 4.0ms preprocess, 115.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 6 alpacas, 127.3ms\n","Speed: 5.1ms preprocess, 127.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 117.5ms\n","Speed: 4.3ms preprocess, 117.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 155.5ms\n","Speed: 4.2ms preprocess, 155.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 127.8ms\n","Speed: 4.2ms preprocess, 127.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 121.4ms\n","Speed: 4.3ms preprocess, 121.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 122.0ms\n","Speed: 5.0ms preprocess, 122.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 124.0ms\n","Speed: 4.0ms preprocess, 124.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 117.5ms\n","Speed: 4.1ms preprocess, 117.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 155.5ms\n","Speed: 3.8ms preprocess, 155.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 122.2ms\n","Speed: 3.8ms preprocess, 122.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 120.3ms\n","Speed: 3.8ms preprocess, 120.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 117.6ms\n","Speed: 3.8ms preprocess, 117.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 122.8ms\n","Speed: 3.7ms preprocess, 122.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 117.9ms\n","Speed: 3.8ms preprocess, 117.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 147.5ms\n","Speed: 5.2ms preprocess, 147.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 128.6ms\n","Speed: 4.8ms preprocess, 128.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 119.6ms\n","Speed: 4.8ms preprocess, 119.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 125.9ms\n","Speed: 4.3ms preprocess, 125.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 123.0ms\n","Speed: 6.0ms preprocess, 123.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 116.7ms\n","Speed: 4.8ms preprocess, 116.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 151.3ms\n","Speed: 3.8ms preprocess, 151.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 122.9ms\n","Speed: 5.0ms preprocess, 122.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 5 alpacas, 127.0ms\n","Speed: 5.0ms preprocess, 127.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 122.3ms\n","Speed: 3.9ms preprocess, 122.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 122.1ms\n","Speed: 3.7ms preprocess, 122.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 122.4ms\n","Speed: 3.9ms preprocess, 122.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 156.2ms\n","Speed: 4.1ms preprocess, 156.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 182.0ms\n","Speed: 4.0ms preprocess, 182.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 183.9ms\n","Speed: 4.2ms preprocess, 183.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 195.4ms\n","Speed: 8.9ms preprocess, 195.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 196.1ms\n","Speed: 4.1ms preprocess, 196.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 187.9ms\n","Speed: 4.0ms preprocess, 187.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 191.2ms\n","Speed: 4.0ms preprocess, 191.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 190.2ms\n","Speed: 4.0ms preprocess, 190.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 211.2ms\n","Speed: 4.4ms preprocess, 211.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 204.8ms\n","Speed: 6.1ms preprocess, 204.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 185.5ms\n","Speed: 4.1ms preprocess, 185.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 185.4ms\n","Speed: 3.8ms preprocess, 185.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 185.9ms\n","Speed: 4.1ms preprocess, 185.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 209.6ms\n","Speed: 4.0ms preprocess, 209.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 200.4ms\n","Speed: 4.1ms preprocess, 200.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 191.2ms\n","Speed: 4.0ms preprocess, 191.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 265.4ms\n","Speed: 3.8ms preprocess, 265.4ms inference, 7.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 222.4ms\n","Speed: 5.2ms preprocess, 222.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 194.6ms\n","Speed: 4.0ms preprocess, 194.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 134.3ms\n","Speed: 6.8ms preprocess, 134.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 134.7ms\n","Speed: 4.8ms preprocess, 134.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 126.8ms\n","Speed: 3.7ms preprocess, 126.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 131.5ms\n","Speed: 3.9ms preprocess, 131.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 119.1ms\n","Speed: 4.1ms preprocess, 119.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 116.6ms\n","Speed: 4.5ms preprocess, 116.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 122.1ms\n","Speed: 3.6ms preprocess, 122.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 149.2ms\n","Speed: 3.7ms preprocess, 149.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 119.6ms\n","Speed: 3.8ms preprocess, 119.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 134.4ms\n","Speed: 4.0ms preprocess, 134.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 122.7ms\n","Speed: 4.9ms preprocess, 122.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 125.5ms\n","Speed: 4.6ms preprocess, 125.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 119.8ms\n","Speed: 6.4ms preprocess, 119.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 133.1ms\n","Speed: 8.1ms preprocess, 133.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 118.5ms\n","Speed: 4.0ms preprocess, 118.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 159.3ms\n","Speed: 3.7ms preprocess, 159.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 116.7ms\n","Speed: 4.8ms preprocess, 116.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 121.2ms\n","Speed: 3.7ms preprocess, 121.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 121.5ms\n","Speed: 5.2ms preprocess, 121.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 131.2ms\n","Speed: 6.1ms preprocess, 131.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 122.5ms\n","Speed: 4.0ms preprocess, 122.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 119.7ms\n","Speed: 4.0ms preprocess, 119.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 121.6ms\n","Speed: 4.1ms preprocess, 121.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 117.5ms\n","Speed: 4.4ms preprocess, 117.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 115.9ms\n","Speed: 4.9ms preprocess, 115.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 143.7ms\n","Speed: 6.8ms preprocess, 143.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 126.5ms\n","Speed: 5.1ms preprocess, 126.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 121.4ms\n","Speed: 3.8ms preprocess, 121.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 137.6ms\n","Speed: 5.2ms preprocess, 137.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 121.1ms\n","Speed: 4.9ms preprocess, 121.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 119.2ms\n","Speed: 4.5ms preprocess, 119.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 129.8ms\n","Speed: 5.0ms preprocess, 129.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 125.3ms\n","Speed: 4.6ms preprocess, 125.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 120.7ms\n","Speed: 7.0ms preprocess, 120.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 129.4ms\n","Speed: 4.7ms preprocess, 129.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 122.8ms\n","Speed: 4.0ms preprocess, 122.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 123.4ms\n","Speed: 5.2ms preprocess, 123.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 129.1ms\n","Speed: 6.5ms preprocess, 129.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 128.7ms\n","Speed: 4.0ms preprocess, 128.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 117.6ms\n","Speed: 4.3ms preprocess, 117.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 134.5ms\n","Speed: 4.8ms preprocess, 134.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 123.0ms\n","Speed: 3.9ms preprocess, 123.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 120.3ms\n","Speed: 4.1ms preprocess, 120.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 135.3ms\n","Speed: 4.9ms preprocess, 135.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 129.3ms\n","Speed: 5.3ms preprocess, 129.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 129.2ms\n","Speed: 4.4ms preprocess, 129.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 132.0ms\n","Speed: 5.9ms preprocess, 132.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 118.5ms\n","Speed: 4.0ms preprocess, 118.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 135.0ms\n","Speed: 3.9ms preprocess, 135.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 127.8ms\n","Speed: 7.9ms preprocess, 127.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 120.4ms\n","Speed: 5.3ms preprocess, 120.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 121.1ms\n","Speed: 4.6ms preprocess, 121.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 131.5ms\n","Speed: 4.9ms preprocess, 131.5ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 125.8ms\n","Speed: 4.7ms preprocess, 125.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 137.3ms\n","Speed: 4.0ms preprocess, 137.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 120.0ms\n","Speed: 4.7ms preprocess, 120.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 119.6ms\n","Speed: 4.5ms preprocess, 119.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 119.0ms\n","Speed: 4.9ms preprocess, 119.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 134.0ms\n","Speed: 3.6ms preprocess, 134.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 150.2ms\n","Speed: 7.3ms preprocess, 150.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 210.5ms\n","Speed: 4.0ms preprocess, 210.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 186.4ms\n","Speed: 4.1ms preprocess, 186.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 184.2ms\n","Speed: 4.0ms preprocess, 184.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 201.7ms\n","Speed: 4.3ms preprocess, 201.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 187.2ms\n","Speed: 3.8ms preprocess, 187.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 184.3ms\n","Speed: 3.9ms preprocess, 184.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 199.4ms\n","Speed: 3.9ms preprocess, 199.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 204.9ms\n","Speed: 5.5ms preprocess, 204.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 190.0ms\n","Speed: 8.2ms preprocess, 190.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 188.4ms\n","Speed: 4.3ms preprocess, 188.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 189.1ms\n","Speed: 4.0ms preprocess, 189.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 183.6ms\n","Speed: 3.9ms preprocess, 183.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 194.9ms\n","Speed: 4.1ms preprocess, 194.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 196.2ms\n","Speed: 4.0ms preprocess, 196.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 201.4ms\n","Speed: 4.1ms preprocess, 201.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 185.1ms\n","Speed: 3.8ms preprocess, 185.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 222.0ms\n","Speed: 4.0ms preprocess, 222.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 189.5ms\n","Speed: 4.0ms preprocess, 189.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 152.3ms\n","Speed: 5.8ms preprocess, 152.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 117.3ms\n","Speed: 3.8ms preprocess, 117.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 118.5ms\n","Speed: 4.4ms preprocess, 118.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 154.2ms\n","Speed: 9.3ms preprocess, 154.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 118.2ms\n","Speed: 3.9ms preprocess, 118.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 121.0ms\n","Speed: 5.1ms preprocess, 121.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 118.4ms\n","Speed: 4.2ms preprocess, 118.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 119.3ms\n","Speed: 4.5ms preprocess, 119.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 118.7ms\n","Speed: 4.9ms preprocess, 118.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 142.8ms\n","Speed: 4.1ms preprocess, 142.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 119.5ms\n","Speed: 8.7ms preprocess, 119.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 119.8ms\n","Speed: 3.7ms preprocess, 119.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 118.8ms\n","Speed: 3.8ms preprocess, 118.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 117.5ms\n","Speed: 3.8ms preprocess, 117.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 120.2ms\n","Speed: 4.0ms preprocess, 120.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 140.2ms\n","Speed: 5.7ms preprocess, 140.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 130.9ms\n","Speed: 3.8ms preprocess, 130.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 118.4ms\n","Speed: 6.5ms preprocess, 118.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 118.4ms\n","Speed: 4.1ms preprocess, 118.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 120.6ms\n","Speed: 5.4ms preprocess, 120.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 119.8ms\n","Speed: 4.8ms preprocess, 119.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 148.1ms\n","Speed: 4.1ms preprocess, 148.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 128.9ms\n","Speed: 6.8ms preprocess, 128.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 116.6ms\n","Speed: 4.2ms preprocess, 116.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 120.7ms\n","Speed: 4.0ms preprocess, 120.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 120.3ms\n","Speed: 5.0ms preprocess, 120.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 115.4ms\n","Speed: 4.3ms preprocess, 115.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 145.1ms\n","Speed: 4.7ms preprocess, 145.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 125.9ms\n","Speed: 6.3ms preprocess, 125.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 114.1ms\n","Speed: 4.0ms preprocess, 114.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 117.0ms\n","Speed: 4.0ms preprocess, 117.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 116.2ms\n","Speed: 4.6ms preprocess, 116.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 117.4ms\n","Speed: 4.7ms preprocess, 117.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 139.8ms\n","Speed: 4.1ms preprocess, 139.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 117.9ms\n","Speed: 3.6ms preprocess, 117.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 119.4ms\n","Speed: 4.3ms preprocess, 119.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 120.2ms\n","Speed: 3.7ms preprocess, 120.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 116.2ms\n","Speed: 3.6ms preprocess, 116.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 121.7ms\n","Speed: 4.1ms preprocess, 121.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 132.7ms\n","Speed: 3.8ms preprocess, 132.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 122.3ms\n","Speed: 4.6ms preprocess, 122.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 135.5ms\n","Speed: 4.0ms preprocess, 135.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 123.0ms\n","Speed: 3.6ms preprocess, 123.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 130.3ms\n","Speed: 6.2ms preprocess, 130.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 119.2ms\n","Speed: 3.7ms preprocess, 119.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 141.4ms\n","Speed: 6.4ms preprocess, 141.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 123.5ms\n","Speed: 5.6ms preprocess, 123.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 130.6ms\n","Speed: 3.9ms preprocess, 130.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 132.0ms\n","Speed: 3.7ms preprocess, 132.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 121.2ms\n","Speed: 3.9ms preprocess, 121.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 119.2ms\n","Speed: 3.6ms preprocess, 119.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 146.1ms\n","Speed: 4.6ms preprocess, 146.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 123.9ms\n","Speed: 4.0ms preprocess, 123.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 134.6ms\n","Speed: 3.8ms preprocess, 134.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 125.9ms\n","Speed: 5.4ms preprocess, 125.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 117.2ms\n","Speed: 4.2ms preprocess, 117.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 121.3ms\n","Speed: 4.1ms preprocess, 121.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 142.0ms\n","Speed: 3.8ms preprocess, 142.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 121.8ms\n","Speed: 4.0ms preprocess, 121.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 125.3ms\n","Speed: 3.9ms preprocess, 125.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 190.5ms\n","Speed: 4.4ms preprocess, 190.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 187.9ms\n","Speed: 4.4ms preprocess, 187.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 198.1ms\n","Speed: 3.9ms preprocess, 198.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 200.9ms\n","Speed: 3.9ms preprocess, 200.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 198.1ms\n","Speed: 4.0ms preprocess, 198.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 181.5ms\n","Speed: 3.8ms preprocess, 181.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 217.8ms\n","Speed: 4.2ms preprocess, 217.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 190.9ms\n","Speed: 3.8ms preprocess, 190.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 195.0ms\n","Speed: 5.4ms preprocess, 195.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 183.3ms\n","Speed: 3.6ms preprocess, 183.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 193.5ms\n","Speed: 4.1ms preprocess, 193.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 177.0ms\n","Speed: 3.7ms preprocess, 177.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 192.2ms\n","Speed: 4.1ms preprocess, 192.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 199.3ms\n","Speed: 3.6ms preprocess, 199.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 207.1ms\n","Speed: 4.1ms preprocess, 207.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 183.7ms\n","Speed: 8.1ms preprocess, 183.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 198.8ms\n","Speed: 4.0ms preprocess, 198.8ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 192.0ms\n","Speed: 3.9ms preprocess, 192.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 191.9ms\n","Speed: 3.9ms preprocess, 191.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 118.4ms\n","Speed: 4.2ms preprocess, 118.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 120.1ms\n","Speed: 3.7ms preprocess, 120.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 121.8ms\n","Speed: 4.0ms preprocess, 121.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 136.8ms\n","Speed: 3.6ms preprocess, 136.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 119.7ms\n","Speed: 5.3ms preprocess, 119.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 131.2ms\n","Speed: 3.8ms preprocess, 131.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 123.7ms\n","Speed: 4.8ms preprocess, 123.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 121.7ms\n","Speed: 5.2ms preprocess, 121.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 121.6ms\n","Speed: 4.1ms preprocess, 121.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 129.1ms\n","Speed: 4.4ms preprocess, 129.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 129.3ms\n","Speed: 5.1ms preprocess, 129.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 129.7ms\n","Speed: 4.3ms preprocess, 129.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 118.1ms\n","Speed: 4.1ms preprocess, 118.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 126.1ms\n","Speed: 4.3ms preprocess, 126.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 121.4ms\n","Speed: 4.2ms preprocess, 121.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 134.9ms\n","Speed: 5.4ms preprocess, 134.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 142.4ms\n","Speed: 3.9ms preprocess, 142.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 125.2ms\n","Speed: 6.4ms preprocess, 125.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 122.5ms\n","Speed: 4.6ms preprocess, 122.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 125.7ms\n","Speed: 4.2ms preprocess, 125.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 alpaca, 143.0ms\n","Speed: 4.8ms preprocess, 143.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 132.6ms\n","Speed: 5.3ms preprocess, 132.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 137.4ms\n","Speed: 4.0ms preprocess, 137.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 120.0ms\n","Speed: 5.5ms preprocess, 120.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 128.5ms\n","Speed: 5.5ms preprocess, 128.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 121.9ms\n","Speed: 3.9ms preprocess, 121.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 119.3ms\n","Speed: 4.9ms preprocess, 119.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 130.2ms\n","Speed: 5.3ms preprocess, 130.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 142.7ms\n","Speed: 5.0ms preprocess, 142.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 125.1ms\n","Speed: 5.2ms preprocess, 125.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 120.3ms\n","Speed: 8.7ms preprocess, 120.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 119.2ms\n","Speed: 7.5ms preprocess, 119.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 124.8ms\n","Speed: 6.7ms preprocess, 124.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 131.3ms\n","Speed: 4.3ms preprocess, 131.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 140.5ms\n","Speed: 3.9ms preprocess, 140.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 119.0ms\n","Speed: 3.9ms preprocess, 119.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 119.2ms\n","Speed: 3.9ms preprocess, 119.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 alpacas, 130.1ms\n","Speed: 3.6ms preprocess, 130.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 alpacas, 120.9ms\n","Speed: 3.7ms preprocess, 120.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 130.8ms\n","Speed: 5.0ms preprocess, 130.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 152.9ms\n","Speed: 3.8ms preprocess, 152.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 alpacas, 118.5ms\n","Speed: 4.5ms preprocess, 118.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","Processed video: alpacaVideos1_out.mp4\n"]}]},{"cell_type":"code","source":["from IPython.display import Video\n","\n","# Videonun yolu\n","video_folder = '/content/gdrive/My Drive/ComputerVisionEngineer/ObjectDetectionYolov8/videos/'\n","\n","# Video dosyasını Colab içinde görüntüle\n","Video(video_folder)\n"],"metadata":{"colab":{"resources":{"http://localhost:8080/content/gdrive/My%20Drive/ComputerVisionEngineer/ObjectDetectionYolov8/videos/":{"data":"","ok":false,"headers":[["content-length","0"]],"status":404,"status_text":""}},"base_uri":"https://localhost:8080/","height":172},"id":"U6oCUTSQB72H","executionInfo":{"status":"ok","timestamp":1731510559424,"user_tz":-180,"elapsed":424,"user":{"displayName":"BugBeauty","userId":"14397405117155400645"}},"outputId":"e62a81bb-576a-4e42-e265-06a6449d430c"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<IPython.core.display.Video object>"],"text/html":["<video src=\"/content/gdrive/My Drive/ComputerVisionEngineer/ObjectDetectionYolov8/videos/\" controls  >\n","      Your browser does not support the <code>video</code> element.\n","    </video>"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":[],"metadata":{"id":"0r829HEyDhIk"},"execution_count":null,"outputs":[]}]}